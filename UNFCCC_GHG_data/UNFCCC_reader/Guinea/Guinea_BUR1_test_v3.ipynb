{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "461e34a0-47b1-44a7-ba1a-77db66ea783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set environment variable (only for jupyter notebook)\n",
    "import os\n",
    "os.environ[\"UNFCCC_GHG_ROOT_PATH\"] = \"/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83dd87db-4956-4bb1-937a-84629bfce95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot\n",
    "import primap2 as pm2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from UNFCCC_GHG_data.helper import process_data_for_country\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from UNFCCC_GHG_data.helper import downloaded_data_path, extracted_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c37d6d49-076c-4823-a486-83fbda3fa33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###\n",
    "# configuration\n",
    "# ###\n",
    "\n",
    "input_folder = downloaded_data_path / 'UNFCCC' / 'Guinea' / 'BUR1'\n",
    "output_folder = extracted_data_path / 'UNFCCC' / 'Guinea'\n",
    "if not output_folder.exists():\n",
    "    output_folder.mkdir()\n",
    "\n",
    "pdf_file = \"Rapport_IGES-Guinee-BUR1_VF.pdf\"\n",
    "output_filename = 'GIN_BUR1_2023_'\n",
    "compression = dict(zlib=True, complevel=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87bf46ce-441e-4247-b62a-ce5ebcf26cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# primap2 format conversion\n",
    "coords_cols = {\n",
    "    \"category\": \"category\",\n",
    "    \"entity\": \"entity\",\n",
    "    \"unit\": \"unit\",\n",
    "}\n",
    "\n",
    "coords_defaults = {\n",
    "    \"source\": \"GIN-GHG-Inventory\",\n",
    "    \"provenance\": \"measured\",\n",
    "    \"area\": \"GIN\",\n",
    "    \"scenario\": \"BUR1\",\n",
    "}\n",
    "\n",
    "coords_terminologies = {\n",
    "    \"area\": \"ISO3\",\n",
    "    # TODO check if this is correct\n",
    "    \"category\": \"IPCC1996_2006_GIN_Inv\",\n",
    "    \"scenario\": \"PRIMAP\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "953ddab6-07ee-4b60-82f0-f2e9ca76b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gwp conversion is mentioned on page 20 in the report\n",
    "gwp_to_use = \"AR4GWP100\"\n",
    "coords_value_mapping = {\n",
    "    'main' : {\n",
    "        \"unit\": \"PRIMAP1\",\n",
    "        \"category\": \"PRIMAP1\",\n",
    "        \"entity\": {\n",
    "            'HFCs': f\"HFCS ({gwp_to_use})\",\n",
    "            'PFCs': f\"PFCS ({gwp_to_use})\",\n",
    "            'SF6' : f\"SF6 ({gwp_to_use})\",\n",
    "            'NMVOCs': 'NMVOC',\n",
    "        }\n",
    "    },\n",
    "    'energy' : {\n",
    "        \"unit\": \"PRIMAP1\",\n",
    "        \"category\": \"PRIMAP1\",\n",
    "        \"entity\": {\n",
    "            'NMVOCs': 'NMVOC',\n",
    "        }\n",
    "    },\n",
    "    'lulucf' : {\n",
    "        \"unit\": \"PRIMAP1\",\n",
    "        \"category\": \"PRIMAP1\",\n",
    "        \"entity\": {\n",
    "            'NMVOCs': 'NMVOC',\n",
    "        }\n",
    "    },\n",
    "    'waste' : {\n",
    "        \"unit\": \"PRIMAP1\",\n",
    "        \"category\": \"PRIMAP1\",\n",
    "        \"entity\": {\n",
    "            'NMVOCs': 'NMVOC',\n",
    "        }\n",
    "    },\n",
    "    'trend' : {\n",
    "        \"unit\": \"PRIMAP1\",\n",
    "        \"category\": \"PRIMAP1\",\n",
    "        \"entity\": {\n",
    "            'NMVOCs': 'NMVOC',\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "# TODO! Don't add MEMO if remove later \n",
    "filter_remove = {\n",
    "    'f_memo': {\"category\": \"MEMO\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23b39c1a-700c-46f9-a3f5-33549658ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = {\n",
    "    \"references\": \"https://unfccc.int/BURs\",\n",
    "    \"rights\": \"\", # unknown\n",
    "    \"contact\": \"daniel-busch@climate-resource.de\",\n",
    "    \"title\": \"Guinea. Biennial update report (BUR). BUR1\",\n",
    "    \"comment\": \"Read fom pdf by Daniel Busch\",\n",
    "    \"institution\": \"UNFCCC\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2390fb91-d976-47f9-9236-a6c838e1fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_def_templates = {\n",
    "    '110': {\n",
    "        \"area\": ['36,718,589,87'],\n",
    "        \"cols\": ['290,340,368,392,425,445,465,497,535,564'],\n",
    "    },\n",
    "    '111': {\n",
    "        \"area\": ['36,736,587,107'],\n",
    "        \"cols\": ['293,335,369,399,424,445,468,497,535,565'],\n",
    "    },\n",
    "    '112': {\n",
    "        \"area\": ['35,733,588,106'],\n",
    "        \"cols\": ['293,335,369,399,424,445,468,497,535,565'],\n",
    "    },\n",
    "    '113': {\n",
    "        \"area\": ['35,733,588,106'],\n",
    "        \"cols\": ['293,335,365,399,424,445,468,497,535,565'],\n",
    "    },\n",
    "    '131' : {\n",
    "                \"area\": ['36,718,590,83'],\n",
    "                \"cols\": ['293,332,370,406,442,480,516,554'],\n",
    "            },\n",
    "}\n",
    "\n",
    "# for main table\n",
    "header_inventory = ['Greenhouse gas source and sink categories',\n",
    "                   'CO2', 'CH4', \"N2O\", 'HFCs', 'PFCs', 'SF6', 'NOx', 'CO', 'NMVOCs','SO2'\n",
    "                   ]\n",
    "\n",
    "unit_inventory = ['-'] + ['Gg'] * len(header_inventory) # one extra for the category columns\n",
    "unit_inventory[4] = \"GgCO2eq\"\n",
    "unit_inventory[5] = \"GgCO2eq\"\n",
    "unit_inventory[6] = \"GgCO2eq\"\n",
    "\n",
    "# for energy tables\n",
    "header_energy = ['Greenhouse gas source and sink categories',\n",
    "                   'CO2', 'CH4', \"N2O\", 'NOx', 'CO', 'NMVOCs','SO2'\n",
    "                ]\n",
    "unit_energy = ['-'] + ['Gg'] * len(header_energy) # one extra for the category columns\n",
    "\n",
    "# for lulucf tables\n",
    "header_lulucf = ['Greenhouse gas source and sink categories', 'CO2', 'CH4', \"N2O\", 'NOx', 'CO', 'NMVOCs']\n",
    "unit_lulucf = ['-'] + ['Gg'] * (len(header_lulucf) - 1)\n",
    "\n",
    "# for waste table\n",
    "header_waste = ['Greenhouse gas source and sink categories', 'CO2', 'CH4', \"N2O\", 'NOx', 'CO', 'NMVOCs', 'SO2']\n",
    "unit_waste = ['-'] + ['Gg'] * (len(header_waste) - 1)\n",
    "\n",
    "# for trend table (unit is always Gg for this table)\n",
    "header_trend = ['data1990', 'data1995', \"data2000\", 'data2005', 'data2010', 'data2015', 'data2018', 'data2019']\n",
    "\n",
    "\n",
    "# define config dict\n",
    "inv_conf = {\n",
    "    'header': header_inventory,\n",
    "    'unit': unit_inventory,\n",
    "    'header_energy' : header_energy,\n",
    "    'unit_energy' : unit_energy,\n",
    "    'header_lulucf' : header_lulucf,\n",
    "    'unit_lulucf' : unit_lulucf,\n",
    "    'header_waste' : header_waste,\n",
    "    'unit_waste' : unit_waste,\n",
    "    'header_trend' : header_trend,\n",
    "    'entity_row': 0,\n",
    "    'unit_row': 1,\n",
    "    'index_cols': \"Greenhouse gas source and sink categories\",\n",
    "    'year': {'110' : 1990,\n",
    "             '111' : 2000,\n",
    "             '112' : 2010,\n",
    "             '113' : 2019,\n",
    "             '116' : 1990,\n",
    "             '117' : 2000,\n",
    "             '118' : 2010,\n",
    "             '119' : 2019,\n",
    "             '124' : 1990,\n",
    "             '125' : 2000,\n",
    "             '126' : 2010,\n",
    "             '127' : 2019,\n",
    "            },\n",
    "    'header_long': [\"orig_cat_name\", \"entity\", \"unit\", \"time\", \"data\"],\n",
    "    \"cat_code_regexp\" : r'^(?P<code>[a-zA-Z0-9\\.]{1,11})[\\s\\.].*',\n",
    "    \"cat_codes_manual\" : {\n",
    "        'main' : {\n",
    "            'Éléments pour mémoire': 'MEMO',\n",
    "            'Soutes internationales': 'M.BK',\n",
    "            '1.A.3.a.i - Aviation internationale (soutes internationales)': 'M.BK.A',\n",
    "            '1.A.3.d.i - Navigation internationale (soutes internationales)' : 'M.BK.M',\n",
    "            '1.A.5.c - Opérations multilatérales' : 'M.MULTIOP',\n",
    "            'Total des émissions et absorptions nationales': \"0\",\n",
    "            '2A5: Autre': '2A5',\n",
    "        },\n",
    "        'energy' : {\n",
    "            'International Bunkers': 'MEMO',\n",
    "            '1.A.3.a.i - Aviation internationale (soutes internationales)': 'M.BK.A',\n",
    "            '1.A.3.d.i - Navigation internationale (soutes internationales)' : 'M.BK.M',\n",
    "            '1.A.5.c - Opérations multilatérales' : 'M.MULTIOP',\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0b97f8-acbb-4df1-9764-b2d0f6af39ba",
   "metadata": {},
   "source": [
    "## 1. Read main tables - pages 110, 111, 112, 113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4357ddd0-e9ee-4b2b-a765-c36411df63e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Reading table from page 110.\n",
      "Reading complete.\n",
      "Added unit information.\n",
      "---------------------------------------------\n",
      "Reading table from page 111.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data/venv/lib/python3.10/site-packages/primap2/pm2io/_GHG_inventory_reading.py:167: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  df_stacked = df_nir.stack([0, 1], dropna=True).to_frame()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading complete.\n",
      "Added unit information.\n",
      "---------------------------------------------\n",
      "Reading table from page 112.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data/venv/lib/python3.10/site-packages/primap2/pm2io/_GHG_inventory_reading.py:167: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  df_stacked = df_nir.stack([0, 1], dropna=True).to_frame()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading complete.\n",
      "Added unit information.\n",
      "---------------------------------------------\n",
      "Reading table from page 113.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data/venv/lib/python3.10/site-packages/primap2/pm2io/_GHG_inventory_reading.py:167: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  df_stacked = df_nir.stack([0, 1], dropna=True).to_frame()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading complete.\n",
      "Added unit information.\n",
      "Converting to interchange format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data/venv/lib/python3.10/site-packages/primap2/pm2io/_GHG_inventory_reading.py:167: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  df_stacked = df_nir.stack([0, 1], dropna=True).to_frame()\n"
     ]
    }
   ],
   "source": [
    "pages = ['110', '111', '112', '113']\n",
    "df_all_dict = {}\n",
    "for page in pages:\n",
    "    \n",
    "    print(\"-\"*45)\n",
    "    print(f\"Reading table from page {page}.\")\n",
    "    \n",
    "    tables_inventory_original = camelot.read_pdf(\n",
    "        str(input_folder / pdf_file),\n",
    "        pages=page,\n",
    "        table_areas=page_def_templates[page][\"area\"],\n",
    "        columns=page_def_templates[page][\"cols\"],\n",
    "        flavor=\"stream\",\n",
    "        split_text=True)\n",
    "    \n",
    "    print(\"Reading complete.\")\n",
    "    \n",
    "    df_inventory = tables_inventory_original[0].df.copy()\n",
    "\n",
    "    # move broken text in correct row (page 113 is fine)\n",
    "    if page in ['110', '111', '112']:\n",
    "        df_inventory.at[4, 0] = \"1.A.1 - Industries énergétiques\"\n",
    "        df_inventory = df_inventory.drop(index=3)\n",
    "        df_inventory.at[8, 0] = \"1.A.4 - Autres secteurs\"\n",
    "        df_inventory = df_inventory.drop(index=7)\n",
    "\n",
    "    # add header and unit\n",
    "    df_header = pd.DataFrame([inv_conf[\"header\"], inv_conf[\"unit\"]])\n",
    "    df_inventory = pd.concat([df_header, df_inventory], axis=0, join='outer').reset_index(drop=True)\n",
    "    df_inventory = pm2.pm2io.nir_add_unit_information(df_inventory,\n",
    "                                                  unit_row=inv_conf[\"unit_row\"],\n",
    "                                                  entity_row=inv_conf[\"entity_row\"],\n",
    "                                                  regexp_entity=\".*\",\n",
    "                                                  regexp_unit=\".*\",\n",
    "                                                  default_unit=\"Gg\")\n",
    "    \n",
    "    print(\"Added unit information.\")\n",
    "    \n",
    "    # set index\n",
    "    df_inventory = df_inventory.set_index(inv_conf[\"index_cols\"])\n",
    "\n",
    "    # convert to long format\n",
    "    df_inventory_long = pm2.pm2io.nir_convert_df_to_long(df_inventory, inv_conf[\"year\"][page],\n",
    "                                                     inv_conf[\"header_long\"])\n",
    "\n",
    "    # extract category from tuple\n",
    "    df_inventory_long[\"orig_cat_name\"] = df_inventory_long[\"orig_cat_name\"].str[0] \n",
    "\n",
    "    # prep for conversion to PM2 IF and native format\n",
    "    # make a copy of the categories row\n",
    "    df_inventory_long[\"category\"] = df_inventory_long[\"orig_cat_name\"]\n",
    "\n",
    "    # replace cat names by codes in col \"category\"\n",
    "    # first the manual replacements\n",
    "    # TODO: move this to config section\n",
    "#    inv_conf[\"cat_codes_manual\"]['main'] = {\n",
    "#            'Éléments pour mémoire': 'MEMO',\n",
    "#            'Soutes internationales': 'M.BK',\n",
    "#            '1.A.3.a.i - Aviation internationale (soutes internationales)': 'M.BK.A',\n",
    "#            '1.A.3.d.i - Navigation internationale (soutes internationales)' : 'M.BK.M',\n",
    "#            '1.A.5.c - Opérations multilatérales' : 'M.MULTIOP',\n",
    "#            'Total des émissions et absorptions nationales': \"0\",\n",
    "#            '2A5: Autre': '2A5', \n",
    "#        }\n",
    "    df_inventory_long[\"category\"] = \\\n",
    "        df_inventory_long[\"category\"].replace(inv_conf[\"cat_codes_manual\"]['main'])  \n",
    "\n",
    "    df_inventory_long[\"category\"] = df_inventory_long[\"category\"].str.replace(\".\", \"\")\n",
    "    \n",
    "    # then the regex replacements\n",
    "    repl = lambda m: m.group('code')\n",
    "    df_inventory_long[\"category\"] = \\\n",
    "        df_inventory_long[\"category\"].str.replace(inv_conf[\"cat_code_regexp\"], repl,\n",
    "                                              regex=True)\n",
    "\n",
    "    df_inventory_long = df_inventory_long.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    \n",
    "    df_inventory_long[\"data\"] = df_inventory_long[\"data\"].str.replace(\",\", \".\")\n",
    "    df_inventory_long[\"data\"] = df_inventory_long[\"data\"].str.replace(\"NE1\", \"NE\")\n",
    "\n",
    "    # make sure all col headers are str\n",
    "    df_inventory_long.columns = df_inventory_long.columns.map(str)\n",
    "    df_inventory_long = df_inventory_long.drop(columns=[\"orig_cat_name\"])\n",
    "    \n",
    "    df_all_dict[page] = df_inventory_long\n",
    "\n",
    "df_all = pd.concat([df_all_dict['110'], df_all_dict['111'], df_all_dict['112'], df_all_dict['113']],\n",
    "                      axis=0,\n",
    "                      join='outer').reset_index(drop=True)\n",
    "\n",
    "print(\"Converting to interchange format.\")\n",
    "df_all_IF = pm2.pm2io.convert_long_dataframe_if(\n",
    "    df_all,\n",
    "    coords_cols=coords_cols,\n",
    "    #add_coords_cols=add_coords_cols,\n",
    "    coords_defaults=coords_defaults,\n",
    "    coords_terminologies=coords_terminologies,\n",
    "    coords_value_mapping=coords_value_mapping['main'],\n",
    "    #coords_value_filling=coords_value_filling,\n",
    "    filter_remove=filter_remove,\n",
    "    #filter_keep=filter_keep,\n",
    "    meta_data=meta_data,\n",
    "    convert_str=True,\n",
    "    time_format=\"%Y\",\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bea1f50-a358-48a8-8e9a-f791fbd63569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are different values for the same categories in the main and lulucf table\n",
    "# it looks like in the main table they put the value from 1990 again for 2019 again\n",
    "# it's unlikely that the value is exactly the same for 1990 and 2019\n",
    "# so I assume the other one is correct\n",
    "df_all_IF.loc[(df_all_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"3\") & (df_all_IF[\"entity\"] == \"CO\") , \"2019\"] = 27.406\n",
    "df_all_IF.loc[(df_all_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"3.C\") & (df_all_IF[\"entity\"] == \"CO\") , \"2019\"] = 27.406\n",
    "df_all_IF.loc[(df_all_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"3.C.1\") & (df_all_IF[\"entity\"] == \"CO\") , \"2019\"] = 27.406\n",
    "\n",
    "# Values for category 3 and N2O are identical for 1990 and 2019\n",
    "# The sum of the sub-categories does not equal the value of the parent category\n",
    "# The value  in the lulucf table should therefore be the correct one\n",
    "df_all_IF.loc[(df_all_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"3\") & (df_all_IF[\"entity\"] == \"N2O\") , \"1990\"] = 2.190\n",
    "\n",
    "# Values for category 3 and NOx are identical for 1990 and 2019\n",
    "# Replacing the duplicate value with the value from the lulucf table\n",
    "df_all_IF.loc[(df_all_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"3\") & (df_all_IF[\"entity\"] == \"NOx\") , \"2019\"] = 1.644\n",
    "df_all_IF.loc[(df_all_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"3.C\") & (df_all_IF[\"entity\"] == \"NOx\") , \"2019\"] = 1.644\n",
    "df_all_IF.loc[(df_all_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"3.C.1\") & (df_all_IF[\"entity\"] == \"NOx\") , \"2019\"] = 1.644"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69fb520a-cc24-4792-95a5-8cbf5387bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all_IF.loc[(df_all_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"1.A.3.a.i\") & (df_all_IF[\"entity\"] == \"N2O\"), \"1990\"].values\n",
    "#df_all_IF.loc[(df_all_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"1.A.3\"), '2010'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1a4535e-3abc-45d0-9309-fd7991b1cb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Testing combination 1.A.1, CO2, 2010.\n",
      "[422.474]\n",
      "Value matches expected value.\n",
      "--------------------------------------------------\n",
      "Testing combination 2, SO2, 1990.\n",
      "[0.097]\n",
      "Value matches expected value.\n",
      "--------------------------------------------------\n",
      "Testing combination M.BK.A, N2O, 2000.\n",
      "[6.e-05]\n",
      "Value matches expected value.\n",
      "--------------------------------------------------\n",
      "Testing combination 2.H.2, NMVOC, 2019.\n",
      "[2.506]\n",
      "Value matches expected value.\n",
      "--------------------------------------------------\n",
      "Testing combination 1.A.1, CH4, 2019.\n",
      "[0.0011]\n",
      "Value matches expected value.\n"
     ]
    }
   ],
   "source": [
    "### Test individual values from the tables ###\n",
    "# TODO and note: this function is work in progress\n",
    "# Use assert statements and print error message\n",
    "# with category, entity, year, expected value and actual value\n",
    "\n",
    "### Test individual values from the tables ###\n",
    "def assert_individual_value(\n",
    "    df,\n",
    "    category_column,\n",
    "    entity_column,\n",
    "    category,\n",
    "    entity,\n",
    "    year,\n",
    "    expected_value\n",
    "):\n",
    "    arr = df.loc[(df[category_column] == category) & (df[entity_column] == entity), year].values\n",
    "    print(arr)\n",
    "    if len(arr) > 1:\n",
    "        print(f\"More than one value found for {category}, {entity}, {year}!\")\n",
    "\n",
    "    # TODO: It looks like this will be true when the value equals 0\n",
    "    if not arr.size > 0:\n",
    "        print((f\"No value found for {category}, {entity}, {year}!\"))\n",
    "            \n",
    "    if not arr[0] == expected_value:\n",
    "        print(f\"Expected value {expected_value}, actual value is {arr[0]}\")\n",
    "\n",
    "    if arr[0] == expected_value:\n",
    "        print(\"Value matches expected value.\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "test_cases = {\n",
    "    \"1\" : {\n",
    "        \"category\" : \"1.A.1\",\n",
    "        'entity' : \"CO2\",\n",
    "        \"year\" : \"2010\",\n",
    "        \"expected_value\" : 422.474,\n",
    "    },\n",
    "    \"2\" : {\n",
    "        \"category\" : \"2\",\n",
    "        'entity' : \"SO2\",\n",
    "        \"year\" : \"1990\",\n",
    "        \"expected_value\" : 0.097,\n",
    "    },\n",
    "    \"3\" : {\n",
    "        \"category\" : \"M.BK.A\",\n",
    "        'entity' : \"N2O\",\n",
    "        \"year\" : \"2000\",\n",
    "        \"expected_value\" : 6e-5,\n",
    "    },\n",
    "    '4' : {\n",
    "        \"category\" : \"2.H.2\",\n",
    "        'entity' : \"NMVOC\",\n",
    "        \"year\" : \"2019\",\n",
    "        \"expected_value\" : 2.506,\n",
    "    },\n",
    "    '5' : {\n",
    "        \"category\" : \"1.A.1\",\n",
    "        'entity' : \"CH4\",\n",
    "        \"year\" : \"2019\",\n",
    "        \"expected_value\" : 0.0011,\n",
    "    }\n",
    "}\n",
    "\n",
    "for key in test_cases.keys():\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Testing combination {test_cases[key]['category']}, {test_cases[key]['entity']}, {test_cases[key]['year']}.\")\n",
    "    assert_individual_value(\n",
    "                    df = df_all_IF,\n",
    "                    category_column = \"category (IPCC1996_2006_GIN_Inv)\",\n",
    "                    entity_column = \"entity\",\n",
    "                    category = test_cases[key][\"category\"],\n",
    "                    entity = test_cases[key][\"entity\"],\n",
    "                    year = test_cases[key][\"year\"],\n",
    "                    expected_value = test_cases[key][\"expected_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23258414-84b2-4a99-8f48-f471f5ebf75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check data for errors ###\n",
    "# print a few things to see if it looks \"normal\"\n",
    "for c in df_all_IF.columns:\n",
    "    print('-'*50)\n",
    "    print(f\"Unique values in column {c}\")\n",
    "    print(df_all_IF[c].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07812254-fb73-4cb5-ae45-a96a2f2273d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-29 12:27:31.256\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2.pm2io._interchange_format\u001b[0m:\u001b[36mfrom_interchange_format\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1mExpected array shapes: [[1, 1, 1, 1, 10, 78], [1, 1, 1, 1, 10, 78], [1, 1, 1, 1, 10, 78], [1, 1, 1, 1, 10, 78], [1, 1, 1, 1, 10, 78], [1, 1, 1, 1, 10, 78], [1, 1, 1, 1, 10, 78], [1, 1, 1, 1, 10, 78], [1, 1, 1, 1, 10, 78], [1, 1, 1, 1, 10, 78]], resulting in size 7,800.\u001b[0m\n",
      "/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data/venv/lib/python3.10/site-packages/primap2/_data_format.py:481: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  all_dims = set(ds.dims.keys())\n",
      "\u001b[32m2024-03-29 12:27:31.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprimap2._data_format\u001b[0m:\u001b[36mensure_valid_attributes\u001b[0m:\u001b[36m292\u001b[0m - \u001b[1mReference information is not a DOI: 'https://unfccc.int/BURs'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### convert to primap2 format ###\n",
    "data_pm2_main = pm2.pm2io.from_interchange_format(df_all_IF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d4e68e-f1f4-4c7d-b710-c749296a16ca",
   "metadata": {},
   "source": [
    "## 2. Read in sector tables for energy - pages 116, 117, 118, 119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "251c3495-8506-4f43-9a97-094b5fb16947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Reading table from page 116.\n",
      "Reading complete.\n",
      "Added unit information.\n",
      "---------------------------------------------\n",
      "Reading table from page 117.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data/venv/lib/python3.10/site-packages/primap2/pm2io/_GHG_inventory_reading.py:167: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  df_stacked = df_nir.stack([0, 1], dropna=True).to_frame()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading complete.\n",
      "Added unit information.\n",
      "---------------------------------------------\n",
      "Reading table from page 118.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data/venv/lib/python3.10/site-packages/primap2/pm2io/_GHG_inventory_reading.py:167: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  df_stacked = df_nir.stack([0, 1], dropna=True).to_frame()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading complete.\n",
      "Added unit information.\n",
      "---------------------------------------------\n",
      "Reading table from page 119.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data/venv/lib/python3.10/site-packages/primap2/pm2io/_GHG_inventory_reading.py:167: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  df_stacked = df_nir.stack([0, 1], dropna=True).to_frame()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading complete.\n",
      "Added unit information.\n",
      "Converting to interchange format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data/venv/lib/python3.10/site-packages/primap2/pm2io/_GHG_inventory_reading.py:167: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  df_stacked = df_nir.stack([0, 1], dropna=True).to_frame()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>scenario (PRIMAP)</th>\n",
       "      <th>provenance</th>\n",
       "      <th>area (ISO3)</th>\n",
       "      <th>entity</th>\n",
       "      <th>unit</th>\n",
       "      <th>category (IPCC1996_2006_GIN_Inv)</th>\n",
       "      <th>1990</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>CH4</td>\n",
       "      <td>Gg CH4 / yr</td>\n",
       "      <td>1</td>\n",
       "      <td>6.465</td>\n",
       "      <td>6.489</td>\n",
       "      <td>4.849</td>\n",
       "      <td>5.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>CH4</td>\n",
       "      <td>Gg CH4 / yr</td>\n",
       "      <td>1.A</td>\n",
       "      <td>6.465</td>\n",
       "      <td>6.489</td>\n",
       "      <td>4.849</td>\n",
       "      <td>5.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>CH4</td>\n",
       "      <td>Gg CH4 / yr</td>\n",
       "      <td>1.A.1</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>CH4</td>\n",
       "      <td>Gg CH4 / yr</td>\n",
       "      <td>1.A.1.a</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>CH4</td>\n",
       "      <td>Gg CH4 / yr</td>\n",
       "      <td>1.A.1.a.i</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>SO2</td>\n",
       "      <td>Gg SO2 / yr</td>\n",
       "      <td>1.A.5.b.iii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>SO2</td>\n",
       "      <td>Gg SO2 / yr</td>\n",
       "      <td>1.A.5.c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>SO2</td>\n",
       "      <td>Gg SO2 / yr</td>\n",
       "      <td>1.B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>SO2</td>\n",
       "      <td>Gg SO2 / yr</td>\n",
       "      <td>M.BK.M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>SO2</td>\n",
       "      <td>Gg SO2 / yr</td>\n",
       "      <td>M.MULTIOP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                source scenario (PRIMAP) provenance area (ISO3) entity  \\\n",
       "0    GIN-GHG-Inventory              BUR1   measured         GIN    CH4   \n",
       "1    GIN-GHG-Inventory              BUR1   measured         GIN    CH4   \n",
       "2    GIN-GHG-Inventory              BUR1   measured         GIN    CH4   \n",
       "3    GIN-GHG-Inventory              BUR1   measured         GIN    CH4   \n",
       "4    GIN-GHG-Inventory              BUR1   measured         GIN    CH4   \n",
       "..                 ...               ...        ...         ...    ...   \n",
       "373  GIN-GHG-Inventory              BUR1   measured         GIN    SO2   \n",
       "374  GIN-GHG-Inventory              BUR1   measured         GIN    SO2   \n",
       "375  GIN-GHG-Inventory              BUR1   measured         GIN    SO2   \n",
       "376  GIN-GHG-Inventory              BUR1   measured         GIN    SO2   \n",
       "377  GIN-GHG-Inventory              BUR1   measured         GIN    SO2   \n",
       "\n",
       "            unit category (IPCC1996_2006_GIN_Inv)   1990   2000   2010   2019  \n",
       "0    Gg CH4 / yr                                1  6.465  6.489  4.849  5.821  \n",
       "1    Gg CH4 / yr                              1.A  6.465  6.489  4.849  5.821  \n",
       "2    Gg CH4 / yr                            1.A.1  0.032  0.024  0.016  0.001  \n",
       "3    Gg CH4 / yr                          1.A.1.a  0.032  0.024  0.016  0.001  \n",
       "4    Gg CH4 / yr                        1.A.1.a.i  0.032  0.024  0.016  0.001  \n",
       "..           ...                              ...    ...    ...    ...    ...  \n",
       "373  Gg SO2 / yr                      1.A.5.b.iii    NaN    NaN    NaN    NaN  \n",
       "374  Gg SO2 / yr                          1.A.5.c    NaN    NaN    NaN    NaN  \n",
       "375  Gg SO2 / yr                              1.B    NaN    NaN    NaN    NaN  \n",
       "376  Gg SO2 / yr                           M.BK.M    NaN    NaN    NaN    NaN  \n",
       "377  Gg SO2 / yr                        M.MULTIOP    NaN    NaN    NaN    NaN  \n",
       "\n",
       "[378 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages = ['116', '117', '118', '119']\n",
    "df_energy_dict = {}\n",
    "for page in pages:\n",
    "    print(\"-\"*45)\n",
    "    print(f\"Reading table from page {page}.\")\n",
    "    \n",
    "    tables_inventory_original = camelot.read_pdf(\n",
    "        str(input_folder / pdf_file),\n",
    "        pages=page,\n",
    "        flavor=\"lattice\",\n",
    "        split_text=True\n",
    "        )\n",
    "    \n",
    "    print(\"Reading complete.\")\n",
    "\n",
    "    # cut last two lines of second table to ignore additional information regarding biomass for energy production \n",
    "    df_energy_year = pd.concat([tables_inventory_original[0].df[2:],\n",
    "                                tables_inventory_original[1].df[3:-2]],\n",
    "                                axis=0,\n",
    "                                join='outer').reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    # drop duplicate lines - 1.A.3.d.i / 1.A.3.a.i / 1.A.5.c\n",
    "    # TODO: better to find the index of the line and then drop it by the index\n",
    "    df_energy_year = df_energy_year.drop(index=[27, 32, 50])  \n",
    "    \n",
    "    # add header and unit\n",
    "    df_header = pd.DataFrame([inv_conf[\"header_energy\"], inv_conf[\"unit_energy\"]])\n",
    "\n",
    "    df_energy_year = pd.concat([df_header, df_energy_year], axis=0, join='outer').reset_index(drop=True)\n",
    "    \n",
    "    df_energy_year = pm2.pm2io.nir_add_unit_information(df_energy_year,\n",
    "                                                  unit_row=inv_conf[\"unit_row\"],\n",
    "                                                  entity_row=inv_conf[\"entity_row\"],\n",
    "                                                  regexp_entity=\".*\",\n",
    "                                                  regexp_unit=\".*\",\n",
    "                                                  default_unit=\"Gg\")\n",
    "    \n",
    "    print(\"Added unit information.\")\n",
    "    # set index\n",
    "    df_energy_year = df_energy_year.set_index(inv_conf[\"index_cols\"])\n",
    "\n",
    "    # convert to long format\n",
    "    df_energy_year_long = pm2.pm2io.nir_convert_df_to_long(df_energy_year, inv_conf[\"year\"][page],\n",
    "                                                     inv_conf[\"header_long\"])\n",
    "    \n",
    "    # extract from tuple\n",
    "    df_energy_year_long[\"orig_cat_name\"] = df_energy_year_long[\"orig_cat_name\"].str[0] \n",
    "\n",
    "    # prep for conversion to PM2 IF and native format\n",
    "    # make a copy of the categories row\n",
    "    df_energy_year_long[\"category\"] = df_energy_year_long[\"orig_cat_name\"]\n",
    "\n",
    "    # replace individual categories\n",
    "    # TODO: move to config section\n",
    "    #inv_conf[\"cat_codes_manual\"]['energy'] = {\n",
    "    #        'International Bunkers': 'MEMO',\n",
    "    #        '1.A.3.a.i - Aviation internationale (soutes internationales)': 'M.BK.A',\n",
    "    #        '1.A.3.d.i - Navigation internationale (soutes internationales)' : 'M.BK.M',\n",
    "    #        '1.A.5.c - Opérations multilatérales' : 'M.MULTIOP',\n",
    "    #    }\n",
    "\n",
    "    # replace cat names by codes in col \"category\"\n",
    "    # first the manual replacements\n",
    "    df_energy_year_long[\"category\"] = df_energy_year_long[\"category\"].str.replace('\\n' ,'')\n",
    "    df_energy_year_long[\"category\"] = \\\n",
    "        df_energy_year_long[\"category\"].replace(inv_conf[\"cat_codes_manual\"]['energy'])\n",
    "\n",
    "    df_energy_year_long[\"category\"] = df_energy_year_long[\"category\"].str.replace(\".\", \"\")\n",
    "    \n",
    "    #inv_conf[\"cat_code_regexp\"] = r'^(?P<code>[a-zA-Z0-9\\.]{1,11})[\\s\\.].*'\n",
    "\n",
    "    # then the regex replacements\n",
    "    repl = lambda m: m.group('code')\n",
    "    df_energy_year_long[\"category\"] = \\\n",
    "        df_energy_year_long[\"category\"].str.replace(inv_conf[\"cat_code_regexp\"], repl,\n",
    "                                              regex=True)\n",
    "\n",
    "    df_energy_year_long = df_energy_year_long.reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    df_energy_year_long[\"data\"] = df_energy_year_long[\"data\"].str.replace(\",\", \".\")\n",
    "    df_energy_year_long[\"data\"] = df_energy_year_long[\"data\"].str.replace(\"NE1\", \"NE\")\n",
    "\n",
    "    # make sure all col headers are str\n",
    "    df_energy_year_long.columns = df_energy_year_long.columns.map(str)\n",
    "    df_energy_year_long = df_energy_year_long.drop(columns=[\"orig_cat_name\"])\n",
    "    \n",
    "    df_energy_dict[page] = df_energy_year_long\n",
    "\n",
    "df_energy = pd.concat([df_energy_dict['116'], df_energy_dict['117'], df_energy_dict['118'], df_energy_dict['119']],\n",
    "                      axis=0,\n",
    "                      join='outer').reset_index(drop=True)\n",
    "\n",
    "print(\"Converting to interchange format.\")\n",
    "df_energy_IF = pm2.pm2io.convert_long_dataframe_if(\n",
    "    df_energy,\n",
    "    coords_cols=coords_cols,\n",
    "    #add_coords_cols=add_coords_cols,\n",
    "    coords_defaults=coords_defaults,\n",
    "    coords_terminologies=coords_terminologies,\n",
    "    coords_value_mapping=coords_value_mapping['energy'],\n",
    "    #coords_value_filling=coords_value_filling,\n",
    "    filter_remove=filter_remove,\n",
    "    #filter_keep=filter_keep,\n",
    "    meta_data=meta_data,\n",
    "    convert_str=True,\n",
    "    time_format=\"%Y\",\n",
    "    )\n",
    "    \n",
    "df_energy_IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51d2a149-ebe0-4404-ae36-0134f10de38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CH4', 'CO', 'CO2', 'N2O', 'NMVOC', 'NOx', 'SO2'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_energy_IF['entity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64fa29dc-f62b-4010-bfed-8cd588675475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Testing combination 1.A.2.k, CH4, 1990.\n",
      "[3.e-05]\n",
      "Value matches expected value.\n",
      "--------------------------------------------------\n",
      "Testing combination 1.A.4.c.i, CO, 1990.\n",
      "[0.0016]\n",
      "Value matches expected value.\n",
      "--------------------------------------------------\n",
      "Testing combination 1.A.3.a.i, NMVOC, 2000.\n",
      "[0.0002]\n",
      "Value matches expected value.\n",
      "--------------------------------------------------\n",
      "Testing combination 1, SO2, 2010.\n",
      "[0.]\n",
      "Value matches expected value.\n",
      "--------------------------------------------------\n",
      "Testing combination 1.A.2.k, N2O, 2019.\n",
      "[7.e-06]\n",
      "Value matches expected value.\n"
     ]
    }
   ],
   "source": [
    "test_cases = {\n",
    "    \"1\" : {\n",
    "        \"category\" : \"1.A.2.k\",\n",
    "        'entity' : \"CH4\",\n",
    "        \"year\" : \"1990\",\n",
    "        \"expected_value\" : 3e-05,\n",
    "    },\n",
    "    \"2\" : {\n",
    "        \"category\" : \"1.A.4.c.i\",\n",
    "        'entity' : \"CO\",\n",
    "        \"year\" : \"1990\",\n",
    "        \"expected_value\" : 0.0016,\n",
    "    },\n",
    "    \"3\" : {\n",
    "        \"category\" : \"1.A.3.a.i\",\n",
    "        'entity' : \"NMVOC\",\n",
    "        \"year\" : \"2000\",\n",
    "        \"expected_value\" : 0.0002,\n",
    "    },\n",
    "    '4' : {\n",
    "        \"category\" : \"1\",\n",
    "        'entity' : \"SO2\",\n",
    "        \"year\" : \"2010\",\n",
    "        \"expected_value\" : 0,\n",
    "    },\n",
    "    '5' : {\n",
    "        \"category\" : \"1.A.2.k\",\n",
    "        'entity' : \"N2O\",\n",
    "        \"year\" : \"2019\",\n",
    "        \"expected_value\" : 7e-06,\n",
    "    }\n",
    "}\n",
    "\n",
    "for key in test_cases.keys():\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Testing combination {test_cases[key]['category']}, {test_cases[key]['entity']}, {test_cases[key]['year']}.\")\n",
    "    assert_individual_value(\n",
    "                    df = df_energy_IF,\n",
    "                    category_column = \"category (IPCC1996_2006_GIN_Inv)\",\n",
    "                    entity_column = \"entity\",\n",
    "                    category = test_cases[key][\"category\"],\n",
    "                    entity = test_cases[key][\"entity\"],\n",
    "                    year = test_cases[key][\"year\"],\n",
    "                    expected_value = test_cases[key][\"expected_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcf727f7-3474-4f2e-9bcb-ebdd140a14c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-29 12:28:16.650\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2.pm2io._interchange_format\u001b[0m:\u001b[36mfrom_interchange_format\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1mExpected array shapes: [[1, 1, 1, 1, 7, 54], [1, 1, 1, 1, 7, 54], [1, 1, 1, 1, 7, 54], [1, 1, 1, 1, 7, 54], [1, 1, 1, 1, 7, 54], [1, 1, 1, 1, 7, 54], [1, 1, 1, 1, 7, 54]], resulting in size 2,646.\u001b[0m\n",
      "/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data/venv/lib/python3.10/site-packages/primap2/_data_format.py:481: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  all_dims = set(ds.dims.keys())\n",
      "\u001b[32m2024-03-29 12:28:16.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprimap2._data_format\u001b[0m:\u001b[36mensure_valid_attributes\u001b[0m:\u001b[36m292\u001b[0m - \u001b[1mReference information is not a DOI: 'https://unfccc.int/BURs'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### convert to primap2 format ###\n",
    "data_pm2_energy = pm2.pm2io.from_interchange_format(df_energy_IF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d557a318-ea3f-44ec-9187-c05da423fbca",
   "metadata": {},
   "source": [
    "# 3. Read in LULUCF table - pages 124, 125, 126, 127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4d117f0-6bfc-468f-b9f2-f66d5eaf8f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Reading table from page 124.\n",
      "Reading complete.\n",
      "Added unit information.\n",
      "---------------------------------------------\n",
      "Reading table from page 125.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data/venv/lib/python3.10/site-packages/primap2/pm2io/_GHG_inventory_reading.py:167: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  df_stacked = df_nir.stack([0, 1], dropna=True).to_frame()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading complete.\n",
      "Added unit information.\n",
      "---------------------------------------------\n",
      "Reading table from page 126.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data/venv/lib/python3.10/site-packages/primap2/pm2io/_GHG_inventory_reading.py:167: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  df_stacked = df_nir.stack([0, 1], dropna=True).to_frame()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading complete.\n",
      "Added unit information.\n",
      "---------------------------------------------\n",
      "Reading table from page 127.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data/venv/lib/python3.10/site-packages/primap2/pm2io/_GHG_inventory_reading.py:167: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  df_stacked = df_nir.stack([0, 1], dropna=True).to_frame()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading complete.\n",
      "Added unit information.\n",
      "Converting to interchange format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data/venv/lib/python3.10/site-packages/primap2/pm2io/_GHG_inventory_reading.py:167: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  df_stacked = df_nir.stack([0, 1], dropna=True).to_frame()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>scenario (PRIMAP)</th>\n",
       "      <th>provenance</th>\n",
       "      <th>area (ISO3)</th>\n",
       "      <th>entity</th>\n",
       "      <th>unit</th>\n",
       "      <th>category (IPCC1996_2006_GIN_Inv)</th>\n",
       "      <th>1990</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>CH4</td>\n",
       "      <td>Gg CH4 / yr</td>\n",
       "      <td>3</td>\n",
       "      <td>56.987</td>\n",
       "      <td>110.568</td>\n",
       "      <td>187.617</td>\n",
       "      <td>299.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>CH4</td>\n",
       "      <td>Gg CH4 / yr</td>\n",
       "      <td>3.A</td>\n",
       "      <td>55.634</td>\n",
       "      <td>107.911</td>\n",
       "      <td>186.769</td>\n",
       "      <td>298.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>CH4</td>\n",
       "      <td>Gg CH4 / yr</td>\n",
       "      <td>3.A.1</td>\n",
       "      <td>53.796</td>\n",
       "      <td>104.298</td>\n",
       "      <td>180.454</td>\n",
       "      <td>288.239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>CH4</td>\n",
       "      <td>Gg CH4 / yr</td>\n",
       "      <td>3.A.1.a</td>\n",
       "      <td>49.050</td>\n",
       "      <td>94.967</td>\n",
       "      <td>161.753</td>\n",
       "      <td>256.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>CH4</td>\n",
       "      <td>Gg CH4 / yr</td>\n",
       "      <td>3.A.1.a.i</td>\n",
       "      <td>10.488</td>\n",
       "      <td>17.802</td>\n",
       "      <td>27.091</td>\n",
       "      <td>31.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>NOx</td>\n",
       "      <td>Gg NOx / yr</td>\n",
       "      <td>3.C.7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>NOx</td>\n",
       "      <td>Gg NOx / yr</td>\n",
       "      <td>3.C.8</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>NOx</td>\n",
       "      <td>Gg NOx / yr</td>\n",
       "      <td>3.D</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>NOx</td>\n",
       "      <td>Gg NOx / yr</td>\n",
       "      <td>3.D.1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>NOx</td>\n",
       "      <td>Gg NOx / yr</td>\n",
       "      <td>3.D.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>474 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                source scenario (PRIMAP) provenance area (ISO3) entity  \\\n",
       "0    GIN-GHG-Inventory              BUR1   measured         GIN    CH4   \n",
       "1    GIN-GHG-Inventory              BUR1   measured         GIN    CH4   \n",
       "2    GIN-GHG-Inventory              BUR1   measured         GIN    CH4   \n",
       "3    GIN-GHG-Inventory              BUR1   measured         GIN    CH4   \n",
       "4    GIN-GHG-Inventory              BUR1   measured         GIN    CH4   \n",
       "..                 ...               ...        ...         ...    ...   \n",
       "469  GIN-GHG-Inventory              BUR1   measured         GIN    NOx   \n",
       "470  GIN-GHG-Inventory              BUR1   measured         GIN    NOx   \n",
       "471  GIN-GHG-Inventory              BUR1   measured         GIN    NOx   \n",
       "472  GIN-GHG-Inventory              BUR1   measured         GIN    NOx   \n",
       "473  GIN-GHG-Inventory              BUR1   measured         GIN    NOx   \n",
       "\n",
       "            unit category (IPCC1996_2006_GIN_Inv)    1990     2000     2010  \\\n",
       "0    Gg CH4 / yr                                3  56.987  110.568  187.617   \n",
       "1    Gg CH4 / yr                              3.A  55.634  107.911  186.769   \n",
       "2    Gg CH4 / yr                            3.A.1  53.796  104.298  180.454   \n",
       "3    Gg CH4 / yr                          3.A.1.a  49.050   94.967  161.753   \n",
       "4    Gg CH4 / yr                        3.A.1.a.i  10.488   17.802   27.091   \n",
       "..           ...                              ...     ...      ...      ...   \n",
       "469  Gg NOx / yr                            3.C.7   0.000    0.000    0.000   \n",
       "470  Gg NOx / yr                            3.C.8   0.000    0.000    0.000   \n",
       "471  Gg NOx / yr                              3.D   0.000    0.000    0.000   \n",
       "472  Gg NOx / yr                            3.D.1   0.000    0.000    0.000   \n",
       "473  Gg NOx / yr                            3.D.2   0.000    0.000    0.000   \n",
       "\n",
       "        2019  \n",
       "0    299.503  \n",
       "1    298.533  \n",
       "2    288.239  \n",
       "3    256.319  \n",
       "4     31.905  \n",
       "..       ...  \n",
       "469    0.000  \n",
       "470    0.000  \n",
       "471    0.000  \n",
       "472    0.000  \n",
       "473    0.000  \n",
       "\n",
       "[474 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages = ['124', '125', '126', '127']\n",
    "df_lulucf_dict = {}\n",
    "for page in pages:\n",
    "    print(\"-\"*45)\n",
    "    print(f\"Reading table from page {page}.\")\n",
    "    \n",
    "    tables_inventory_original = camelot.read_pdf(\n",
    "    str(input_folder / pdf_file),\n",
    "    pages=page,\n",
    "    flavor=\"lattice\",\n",
    "    split_text=True\n",
    "    )\n",
    "    print(\"Reading complete.\")\n",
    "\n",
    "    if page == '127':\n",
    "        # table on page 127 has one extra row at the top\n",
    "        # and one extra category 3.A.1.j\n",
    "        df_lulucf_year = tables_inventory_original[0].df[3:]\n",
    "        # rename duplicate categories in tables\n",
    "        # TODO move to config section\n",
    "        replace_categories = [(19, \"3.A.2.a.i - Vaches laitières\"),\n",
    "                              (20, \"3.A.2.a.ii - Autres bovins\"),\n",
    "                              (21, \"3.A.2.b - Buffle\"),\n",
    "                              (22, \"3.A.2.c - Ovins\"),\n",
    "                              (23, \"3.A.2.d - Caprins\"),\n",
    "                              (24, \"3.A.2.e - Chameaux\"),\n",
    "                              (25, \"3.A.2.f - Chevaux\"),\n",
    "                              (26, \"3.A.2.g - Mules et ânes\"),\n",
    "                              (27, \"3.A.2.h - Porcins\"),\n",
    "                              (28, \"3.A.2.i - Volailles\"),\n",
    "                              (29, \"3.A.2.j - Autres (préciser)\"),]\n",
    "        for index, category_name in  replace_categories:\n",
    "            df_lulucf_year.at[index, 0] = category_name\n",
    "    else:\n",
    "        # cut first two lines\n",
    "        df_lulucf_year = tables_inventory_original[0].df[2:] \n",
    "\n",
    "        # TODO move to config section\n",
    "        replace_categories = [(17, \"3.A.2.a.i - Vaches laitières\"),\n",
    "                              (18, \"3.A.2.a.ii - Autres bovins\"),\n",
    "                              (19, \"3.A.2.b - Buffle\"),\n",
    "                              (20, \"3.A.2.c - Ovins\"),\n",
    "                              (21, \"3.A.2.d - Caprins\"),\n",
    "                              (22, \"3.A.2.e - Chameaux\"),\n",
    "                              (23, \"3.A.2.f - Chevaux\"),\n",
    "                              (24, \"3.A.2.g - Mules et ânes\"),\n",
    "                              (25, \"3.A.2.h - Porcins\"),\n",
    "                              (26, \"3.A.2.i - Volailles\"),]\n",
    "        for index, category_name in  replace_categories:\n",
    "            df_lulucf_year.at[index, 0] = category_name\n",
    "    \n",
    "    # add header and unit\n",
    "    df_header = pd.DataFrame([inv_conf[\"header_lulucf\"], inv_conf[\"unit_lulucf\"]])\n",
    "\n",
    "    df_lulucf_year = pd.concat([df_header, df_lulucf_year], axis=0, join='outer').reset_index(drop=True)\n",
    "\n",
    "    df_lulucf_year = pm2.pm2io.nir_add_unit_information(df_lulucf_year,\n",
    "                                                  unit_row=inv_conf[\"unit_row\"],\n",
    "                                                  entity_row=inv_conf[\"entity_row\"],\n",
    "                                                  regexp_entity=\".*\",\n",
    "                                                  regexp_unit=\".*\",\n",
    "                                                  default_unit=\"Gg\")\n",
    "\n",
    "    print(\"Added unit information.\")\n",
    "    \n",
    "    # set index\n",
    "    df_lulucf_year = df_lulucf_year.set_index(inv_conf[\"index_cols\"])\n",
    "\n",
    "    # convert to long format\n",
    "    df_lulucf_year_long = pm2.pm2io.nir_convert_df_to_long(df_lulucf_year, inv_conf[\"year\"][page],\n",
    "                                                     inv_conf[\"header_long\"])\n",
    "    \n",
    "    df_lulucf_year_long[\"orig_cat_name\"] = df_lulucf_year_long[\"orig_cat_name\"].str[0] # extract from tuple\n",
    "\n",
    "    # prep for conversion to PM2 IF and native format\n",
    "    # make a copy of the categories row\n",
    "    df_lulucf_year_long[\"category\"] = df_lulucf_year_long[\"orig_cat_name\"]\n",
    "   \n",
    "    # regex replacements\n",
    "    repl = lambda m: m.group('code')\n",
    "    df_lulucf_year_long[\"category\"] = \\\n",
    "        df_lulucf_year_long[\"category\"].str.replace(inv_conf[\"cat_code_regexp\"], repl,\n",
    "                                              regex=True)\n",
    "    \n",
    "    df_lulucf_year_long = df_lulucf_year_long.reset_index(drop=True)\n",
    "    \n",
    "    df_lulucf_year_long[\"data\"] = df_lulucf_year_long[\"data\"].str.replace(\",\", \".\")\n",
    "    df_lulucf_year_long[\"data\"] = df_lulucf_year_long[\"data\"].str.replace(\"NE1\", \"NE\")\n",
    "\n",
    "    # make sure all col headers are str\n",
    "    df_lulucf_year_long.columns = df_lulucf_year_long.columns.map(str)\n",
    "    df_lulucf_year_long = df_lulucf_year_long.drop(columns=[\"orig_cat_name\"])\n",
    "    \n",
    "    df_lulucf_dict[page] = df_lulucf_year_long\n",
    "\n",
    "df_lulucf = pd.concat([df_lulucf_dict['124'], df_lulucf_dict['125'], df_lulucf_dict['126'], df_lulucf_dict['127']],\n",
    "                      axis=0,\n",
    "                      join='outer').reset_index(drop=True)\n",
    "\n",
    "print(\"Converting to interchange format.\")\n",
    "df_lulucf_IF = pm2.pm2io.convert_long_dataframe_if(\n",
    "    df_lulucf,\n",
    "    coords_cols=coords_cols,\n",
    "    #add_coords_cols=add_coords_cols,\n",
    "    coords_defaults=coords_defaults,\n",
    "    coords_terminologies=coords_terminologies,\n",
    "    coords_value_mapping=coords_value_mapping['lulucf'],\n",
    "    #coords_value_filling=coords_value_filling,\n",
    "    filter_remove=filter_remove,\n",
    "    #filter_keep=filter_keep,\n",
    "    meta_data=meta_data,\n",
    "    convert_str=True,\n",
    "    time_format=\"%Y\",\n",
    "    )\n",
    "    \n",
    "df_lulucf_IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6599b99f-aad2-4230-b784-f8e406c58bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CH4', 'CO', 'CO2', 'N2O', 'NMVOC', 'NOx'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lulucf_IF['entity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d132ea2-655a-4363-9171-b81904a7d6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-29 12:29:29.030\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2.pm2io._interchange_format\u001b[0m:\u001b[36mfrom_interchange_format\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1mExpected array shapes: [[1, 1, 1, 1, 6, 79], [1, 1, 1, 1, 6, 79], [1, 1, 1, 1, 6, 79], [1, 1, 1, 1, 6, 79], [1, 1, 1, 1, 6, 79], [1, 1, 1, 1, 6, 79]], resulting in size 2,844.\u001b[0m\n",
      "/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data/venv/lib/python3.10/site-packages/primap2/_data_format.py:481: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  all_dims = set(ds.dims.keys())\n",
      "\u001b[32m2024-03-29 12:29:29.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprimap2._data_format\u001b[0m:\u001b[36mensure_valid_attributes\u001b[0m:\u001b[36m292\u001b[0m - \u001b[1mReference information is not a DOI: 'https://unfccc.int/BURs'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### convert to primap2 format ###\n",
    "data_pm2_lulucf = pm2.pm2io.from_interchange_format(df_lulucf_IF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99c689e-1f26-42d5-8974-194373ce26f6",
   "metadata": {},
   "source": [
    "# 3. Read in Waste tables - pages 128, 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcf17dba-6af4-400f-9ec3-b5dd5b1b0a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are three tables for three years on page 128\n",
    "# and another tabel on page 130\n",
    "\n",
    "# read three tables\n",
    "page = '128'\n",
    "tables_inventory_original_128 = camelot.read_pdf(\n",
    "    str(input_folder / pdf_file),\n",
    "    pages=page,\n",
    "    flavor=\"lattice\",\n",
    "    split_text=True\n",
    ")\n",
    "\n",
    "# read last table\n",
    "page = '130'\n",
    "tables_inventory_original_130 = camelot.read_pdf(\n",
    "    str(input_folder / pdf_file),\n",
    "    pages=page,\n",
    "    flavor=\"lattice\",\n",
    "    split_text=True\n",
    ")\n",
    "\n",
    "# save to dict\n",
    "df_waste_years = {\n",
    "    '1990' : tables_inventory_original_128[0].df,\n",
    "    '2000' : tables_inventory_original_128[1].df,\n",
    "    '2010' : tables_inventory_original_128[2].df,\n",
    "    '2019' : tables_inventory_original_130[0].df,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e0afb6e-db8b-41ae-b02d-e4a5d54ea5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Processing table for 1990.\n",
      "Added unit information.\n",
      "---------------------------------------------\n",
      "Processing table for 2000.\n",
      "Added unit information.\n",
      "---------------------------------------------\n",
      "Processing table for 2010.\n",
      "Added unit information.\n",
      "---------------------------------------------\n",
      "Processing table for 2019.\n",
      "Added unit information.\n",
      "Converting to interchange format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data/venv/lib/python3.10/site-packages/primap2/pm2io/_GHG_inventory_reading.py:167: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  df_stacked = df_nir.stack([0, 1], dropna=True).to_frame()\n",
      "/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data/venv/lib/python3.10/site-packages/primap2/pm2io/_GHG_inventory_reading.py:167: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  df_stacked = df_nir.stack([0, 1], dropna=True).to_frame()\n",
      "/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data/venv/lib/python3.10/site-packages/primap2/pm2io/_GHG_inventory_reading.py:167: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  df_stacked = df_nir.stack([0, 1], dropna=True).to_frame()\n",
      "/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data/venv/lib/python3.10/site-packages/primap2/pm2io/_GHG_inventory_reading.py:167: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  df_stacked = df_nir.stack([0, 1], dropna=True).to_frame()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>scenario (PRIMAP)</th>\n",
       "      <th>provenance</th>\n",
       "      <th>area (ISO3)</th>\n",
       "      <th>entity</th>\n",
       "      <th>unit</th>\n",
       "      <th>category (IPCC1996_2006_GIN_Inv)</th>\n",
       "      <th>1990</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>CH4</td>\n",
       "      <td>Gg CH4 / yr</td>\n",
       "      <td>4</td>\n",
       "      <td>1.750</td>\n",
       "      <td>2.925</td>\n",
       "      <td>4.534</td>\n",
       "      <td>6.665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>CH4</td>\n",
       "      <td>Gg CH4 / yr</td>\n",
       "      <td>4.A</td>\n",
       "      <td>1.029</td>\n",
       "      <td>2.054</td>\n",
       "      <td>3.323</td>\n",
       "      <td>5.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>CH4</td>\n",
       "      <td>Gg CH4 / yr</td>\n",
       "      <td>4.A.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>CH4</td>\n",
       "      <td>Gg CH4 / yr</td>\n",
       "      <td>4.A.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>CH4</td>\n",
       "      <td>Gg CH4 / yr</td>\n",
       "      <td>4.A.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>SO2</td>\n",
       "      <td>Gg SO2 / yr</td>\n",
       "      <td>4.C.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>SO2</td>\n",
       "      <td>Gg SO2 / yr</td>\n",
       "      <td>4.D</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>SO2</td>\n",
       "      <td>Gg SO2 / yr</td>\n",
       "      <td>4.D.1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>SO2</td>\n",
       "      <td>Gg SO2 / yr</td>\n",
       "      <td>4.D.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>SO2</td>\n",
       "      <td>Gg SO2 / yr</td>\n",
       "      <td>4.E</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               source scenario (PRIMAP) provenance area (ISO3) entity  \\\n",
       "0   GIN-GHG-Inventory              BUR1   measured         GIN    CH4   \n",
       "1   GIN-GHG-Inventory              BUR1   measured         GIN    CH4   \n",
       "2   GIN-GHG-Inventory              BUR1   measured         GIN    CH4   \n",
       "3   GIN-GHG-Inventory              BUR1   measured         GIN    CH4   \n",
       "4   GIN-GHG-Inventory              BUR1   measured         GIN    CH4   \n",
       "..                ...               ...        ...         ...    ...   \n",
       "86  GIN-GHG-Inventory              BUR1   measured         GIN    SO2   \n",
       "87  GIN-GHG-Inventory              BUR1   measured         GIN    SO2   \n",
       "88  GIN-GHG-Inventory              BUR1   measured         GIN    SO2   \n",
       "89  GIN-GHG-Inventory              BUR1   measured         GIN    SO2   \n",
       "90  GIN-GHG-Inventory              BUR1   measured         GIN    SO2   \n",
       "\n",
       "           unit category (IPCC1996_2006_GIN_Inv)   1990   2000   2010   2019  \n",
       "0   Gg CH4 / yr                                4  1.750  2.925  4.534  6.665  \n",
       "1   Gg CH4 / yr                              4.A  1.029  2.054  3.323  5.170  \n",
       "2   Gg CH4 / yr                            4.A.1    NaN    NaN    NaN    NaN  \n",
       "3   Gg CH4 / yr                            4.A.2    NaN    NaN    NaN    NaN  \n",
       "4   Gg CH4 / yr                            4.A.3    NaN    NaN    NaN    NaN  \n",
       "..          ...                              ...    ...    ...    ...    ...  \n",
       "86  Gg SO2 / yr                            4.C.2  0.000  0.000  0.000  0.000  \n",
       "87  Gg SO2 / yr                              4.D  0.000  0.000  0.000  0.000  \n",
       "88  Gg SO2 / yr                            4.D.1  0.000  0.000  0.000  0.000  \n",
       "89  Gg SO2 / yr                            4.D.2  0.000  0.000  0.000  0.000  \n",
       "90  Gg SO2 / yr                              4.E  0.000  0.000  0.000  0.000  \n",
       "\n",
       "[91 rows x 11 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_waste_dict = {}\n",
    "for year in df_waste_years.keys():\n",
    "    print(\"-\"*45)\n",
    "    print(f\"Processing table for {year}.\")\n",
    "\n",
    "    df_waste_year = df_waste_years[year][2:]\n",
    "    \n",
    "    # add header and unit\n",
    "    df_header = pd.DataFrame([inv_conf[\"header_waste\"], inv_conf[\"unit_waste\"]])\n",
    "\n",
    "    df_waste_year = pd.concat([df_header, df_waste_year], axis=0, join='outer').reset_index(drop=True)\n",
    "\n",
    "    df_waste_year = pm2.pm2io.nir_add_unit_information(df_waste_year,\n",
    "                                                  unit_row=inv_conf[\"unit_row\"],\n",
    "                                                  entity_row=inv_conf[\"entity_row\"],\n",
    "                                                  regexp_entity=\".*\",\n",
    "                                                  regexp_unit=\".*\",\n",
    "                                                  default_unit=\"Gg\")\n",
    "\n",
    "    print(\"Added unit information.\")\n",
    "    \n",
    "    # set index\n",
    "    df_waste_year = df_waste_year.set_index(inv_conf[\"index_cols\"])\n",
    "\n",
    "    # convert to long format\n",
    "    df_waste_year_long = pm2.pm2io.nir_convert_df_to_long(df_waste_year, year,\n",
    "                                                     inv_conf[\"header_long\"])\n",
    "    \n",
    "    df_waste_year_long[\"orig_cat_name\"] = df_waste_year_long[\"orig_cat_name\"].str[0]\n",
    "\n",
    "    # prep for conversion to PM2 IF and native format\n",
    "    # make a copy of the categories row\n",
    "    df_waste_year_long[\"category\"] = df_waste_year_long[\"orig_cat_name\"]\n",
    "\n",
    "    # regex replacements\n",
    "    repl = lambda m: m.group('code')\n",
    "    df_waste_year_long[\"category\"] = \\\n",
    "        df_waste_year_long[\"category\"].str.replace(inv_conf[\"cat_code_regexp\"], repl,\n",
    "                                              regex=True)\n",
    "    \n",
    "    df_waste_year_long = df_waste_year_long.reset_index(drop=True)\n",
    "\n",
    "    df_waste_year_long[\"category\"] = df_waste_year_long[\"category\"].str.replace(\".\", \"\")\n",
    "    df_waste_year_long[\"data\"] = df_waste_year_long[\"data\"].str.replace(\",\", \".\")\n",
    "    df_waste_year_long[\"data\"] = df_waste_year_long[\"data\"].str.replace(\"NE1\", \"NE\")\n",
    "\n",
    "    # make sure all col headers are str\n",
    "    df_waste_year_long.columns = df_waste_year_long.columns.map(str)\n",
    "    df_waste_year_long = df_waste_year_long.drop(columns=[\"orig_cat_name\"])\n",
    "    \n",
    "    df_waste_dict[year] = df_waste_year_long\n",
    "\n",
    "df_waste = pd.concat([df_waste_dict['1990'], df_waste_dict['2000'], df_waste_dict['2010'], df_waste_dict['2019']],\n",
    "                      axis=0,\n",
    "                      join='outer').reset_index(drop=True)\n",
    "\n",
    "print(\"Converting to interchange format.\")\n",
    "df_waste_IF = pm2.pm2io.convert_long_dataframe_if(\n",
    "    df_waste,\n",
    "    coords_cols=coords_cols,\n",
    "    #add_coords_cols=add_coords_cols,\n",
    "    coords_defaults=coords_defaults,\n",
    "    coords_terminologies=coords_terminologies,\n",
    "    coords_value_mapping=coords_value_mapping['waste'],\n",
    "    #coords_value_filling=coords_value_filling,\n",
    "    filter_remove=filter_remove,\n",
    "    #filter_keep=filter_keep,\n",
    "    meta_data=meta_data,\n",
    "    convert_str=True,\n",
    "    time_format=\"%Y\",\n",
    "    )\n",
    "    \n",
    "df_waste_IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6628eacb-8a24-415b-a42e-04e929976f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-29 12:29:37.042\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2.pm2io._interchange_format\u001b[0m:\u001b[36mfrom_interchange_format\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1mExpected array shapes: [[1, 1, 1, 1, 7, 13], [1, 1, 1, 1, 7, 13], [1, 1, 1, 1, 7, 13], [1, 1, 1, 1, 7, 13], [1, 1, 1, 1, 7, 13], [1, 1, 1, 1, 7, 13], [1, 1, 1, 1, 7, 13]], resulting in size 637.\u001b[0m\n",
      "/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data/venv/lib/python3.10/site-packages/primap2/_data_format.py:481: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  all_dims = set(ds.dims.keys())\n",
      "\u001b[32m2024-03-29 12:29:37.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprimap2._data_format\u001b[0m:\u001b[36mensure_valid_attributes\u001b[0m:\u001b[36m292\u001b[0m - \u001b[1mReference information is not a DOI: 'https://unfccc.int/BURs'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### convert to primap2 format ###\n",
    "data_pm2_waste = pm2.pm2io.from_interchange_format(df_waste_IF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba512153-1c65-4568-9bae-817fbf9cc9b3",
   "metadata": {},
   "source": [
    "# 4. Read in trend tables - pages 131 - 137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44572286-cebe-4974-9476-ea9eb7453fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Reading table for page 131 and entity CO2.\n",
      "Reading complete.\n",
      "Created category codes.\n",
      "Converted to long format.\n",
      "---------------------------------------------\n",
      "Reading table for page 132 and entity CH4.\n",
      "Reading complete.\n",
      "Created category codes.\n",
      "Converted to long format.\n",
      "---------------------------------------------\n",
      "Reading table for page 133 and entity N2O.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/4093200453.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend_entity.loc[:, 'unit'] = 'Gg'\n",
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/4093200453.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend_entity.loc[:,'entity'] = entity\n",
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/4093200453.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend_entity.loc[:, \"category\"] = df_trend_entity[\"orig_cat_name\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading complete.\n",
      "Created category codes.\n",
      "Converted to long format.\n",
      "---------------------------------------------\n",
      "Reading table for page 134 and entity NOx.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/4093200453.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend_entity.loc[:, 'unit'] = 'Gg'\n",
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/4093200453.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend_entity.loc[:,'entity'] = entity\n",
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/4093200453.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend_entity.loc[:, \"category\"] = df_trend_entity[\"orig_cat_name\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading complete.\n",
      "Created category codes.\n",
      "Converted to long format.\n",
      "---------------------------------------------\n",
      "Reading table for page 135 and entity CO.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/4093200453.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend_entity.loc[:, 'unit'] = 'Gg'\n",
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/4093200453.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend_entity.loc[:,'entity'] = entity\n",
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/4093200453.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend_entity.loc[:, \"category\"] = df_trend_entity[\"orig_cat_name\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading complete.\n",
      "Created category codes.\n",
      "Converted to long format.\n",
      "---------------------------------------------\n",
      "Reading table for page 136 and entity NMVOCs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/4093200453.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend_entity.loc[:, 'unit'] = 'Gg'\n",
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/4093200453.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend_entity.loc[:,'entity'] = entity\n",
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/4093200453.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend_entity.loc[:, \"category\"] = df_trend_entity[\"orig_cat_name\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading complete.\n",
      "Created category codes.\n",
      "Converted to long format.\n",
      "---------------------------------------------\n",
      "Reading table for page 137 and entity SO2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/4093200453.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend_entity.loc[:, 'unit'] = 'Gg'\n",
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/4093200453.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend_entity.loc[:,'entity'] = entity\n",
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/4093200453.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend_entity.loc[:, \"category\"] = df_trend_entity[\"orig_cat_name\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading complete.\n",
      "Created category codes.\n",
      "Converted to long format.\n",
      "Converting to interchange format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/4093200453.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend_entity.loc[:, 'unit'] = 'Gg'\n",
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/4093200453.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend_entity.loc[:,'entity'] = entity\n",
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/4093200453.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_trend_entity.loc[:, \"category\"] = df_trend_entity[\"orig_cat_name\"]\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib widget \n",
    "#camelot.plot(tables_inventory_original[0], kind='text')\n",
    "\n",
    "df_main_dict = {}\n",
    "pages = ['131', '132', '133', '134', '135', '136', '137']\n",
    "entities = ['CO2', 'CH4', 'N2O', 'NOx', 'CO', 'NMVOCs', 'SO2']\n",
    "\n",
    "# for this set of tables every page is a different entity\n",
    "for page, entity in zip(pages, entities):\n",
    "\n",
    "    print(\"-\"*45)\n",
    "    print(f\"Reading table for page {page} and entity {entity}.\")\n",
    "    \n",
    "    # first table needs to be read in with flavor=\"stream\"\n",
    "    # flavor=\"lattice\" raises an error, maybe camelot issue\n",
    "    # see https://github.com/atlanhq/camelot/issues/306\n",
    "    # or because characters in first row almost reach\n",
    "    # the table grid    \n",
    "    if page == '131':\n",
    "        tables_inventory_original = camelot.read_pdf(\n",
    "            str(input_folder / pdf_file),\n",
    "            pages=page,\n",
    "            table_areas=page_def_templates[page][\"area\"],\n",
    "            columns=page_def_templates[page][\"cols\"],\n",
    "            flavor=\"stream\",\n",
    "            split_text=True\n",
    "        )\n",
    "        \n",
    "        df_trend_entity = tables_inventory_original[0].df[1:]\n",
    "\n",
    "        # these rows are different to the main table and don't make sense\n",
    "        row_to_delete = df_trend_entity.index[df_trend_entity[0] == '3.D - Autres'][0]\n",
    "        df_trend_entity = df_trend_entity.drop(index = row_to_delete)\n",
    "\n",
    "        row_to_delete = df_trend_entity.index[df_trend_entity[0] == '3.D.1 - Produits ligneux récoltés'][0]\n",
    "        df_trend_entity = df_trend_entity.drop(index = row_to_delete)\n",
    "\n",
    "        row_to_delete = df_trend_entity.index[df_trend_entity[0] == '3.D.2 - Autres (veuillez spécifier)'][0]\n",
    "        df_trend_entity = df_trend_entity.drop(index = row_to_delete)\n",
    "   \n",
    "    else:\n",
    "        tables_inventory_original = camelot.read_pdf(\n",
    "            str(input_folder / pdf_file),\n",
    "            pages=page,\n",
    "            flavor=\"lattice\",\n",
    "            split_text=True)\n",
    "        df_trend_entity = tables_inventory_original[0].df[3:]\n",
    "\n",
    "    print(f\"Reading complete.\")\n",
    "\n",
    "    # add columns\n",
    "    # 'data' prefix is needed for pd.wide_to_long() later\n",
    "    columns_years = ['data1990', 'data1995', \"data2000\", 'data2005', 'data2010', 'data2015', 'data2018', 'data2019']\n",
    "    df_trend_entity.columns = ['orig_cat_name'] + columns_years\n",
    "    \n",
    "    # unit is always Gg\n",
    "    df_trend_entity.loc[:, 'unit'] = 'Gg'\n",
    "    \n",
    "    # only one entity per table\n",
    "    df_trend_entity.loc[:,'entity'] = entity\n",
    "    \n",
    "    df_trend_entity.loc[:, \"category\"] = df_trend_entity[\"orig_cat_name\"]\n",
    "\n",
    "    # delete rows that are just a headline or empty\n",
    "    #row_to_delete = df_trend_entity.index[df_trend_entity['category'] == 'Éléments pour mémoire'][0]\n",
    "    #df_trend_entity = df_trend_entity.drop(index = row_to_delete)\n",
    "\n",
    "    # in the first table there is no empty line\n",
    "    if page != '131':\n",
    "        row_to_delete = df_trend_entity.index[df_trend_entity['category'] == ''][0]\n",
    "        df_trend_entity = df_trend_entity.drop(index = row_to_delete)\n",
    "    \n",
    "    inv_conf[\"cat_code_regexp\"] = r'^(?P<code>[a-zA-Z0-9\\.]{1,11})[\\s\\.].*'\n",
    "\n",
    "    df_trend_entity[\"category\"] = df_trend_entity[\"category\"].replace(\n",
    "        {\n",
    "         'Total des émissions et absorptions nationales': \"0\",\n",
    "         '2A5: Autre' : '2A5',\n",
    "         'Éléments pour mémoire': 'MEMO',\n",
    "         'Soutes internationales' : 'M.BK',\n",
    "         '1.A.3.a.i - Aviation internationale (soutes internationales)' : 'M.BK.A',\n",
    "         '1.A.3.d.i - Navigation internationale (soutes internationales)' : 'M.BK.M',\n",
    "         '1.A.5.c - Opérations multilatérales' : 'M.MULTIOP',\n",
    "        })\n",
    "\n",
    "    df_trend_entity.loc[:, \"category\"] = df_trend_entity[\"category\"].str.replace(\".\", \"\")\n",
    "    df_trend_entity.loc[:, \"category\"] = df_trend_entity[\"category\"].str.replace(\"\\n\", \"\")\n",
    "    \n",
    "    \n",
    "    repl = lambda m: m.group('code')\n",
    "    df_trend_entity.loc[:, \"category\"] = \\\n",
    "        df_trend_entity[\"category\"].str.replace(inv_conf[\"cat_code_regexp\"], repl,\n",
    "                                              regex=True)\n",
    "    \n",
    "    df_trend_entity = df_trend_entity.reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Created category codes.\")\n",
    "\n",
    "    if entity == 'CO':\n",
    "        df_trend_entity = df_trend_entity.drop(columns=['data2010', 'data2000', 'data2019'])\n",
    "        columns_years = ['data1990', 'data1995', 'data2005', 'data2015', 'data2018']\n",
    "\n",
    "    for year in columns_years:\n",
    "        df_trend_entity.loc[:, year] = df_trend_entity[year].str.replace(\",\", \".\")\n",
    "        df_trend_entity.loc[:, year] = df_trend_entity[year].str.replace(\"NE1\", \"NE\")\n",
    "    \n",
    "    # make sure all col headers are str\n",
    "    df_trend_entity.columns = df_trend_entity.columns.map(str)\n",
    "    \n",
    "    df_trend_entity = df_trend_entity.drop(columns=[\"orig_cat_name\"])\n",
    "\n",
    "    # TODO wide in IF gibt es convert_wide_dataframe_if\n",
    "    df_trend_entity_long = pd.wide_to_long(df_trend_entity, stubnames='data',  i='category', j='time')\n",
    "    \n",
    "    print(f\"Converted to long format.\")\n",
    "    \n",
    "    df_trend_entity_long = df_trend_entity_long.reset_index()\n",
    "    \n",
    "    df_main_dict[page] =  df_trend_entity_long\n",
    "\n",
    "print(\"Converting to interchange format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b94b277d-0d28-4d6c-9afd-7d66ef211cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>scenario (PRIMAP)</th>\n",
       "      <th>provenance</th>\n",
       "      <th>area (ISO3)</th>\n",
       "      <th>entity</th>\n",
       "      <th>unit</th>\n",
       "      <th>category (IPCC1996_2006_GIN_Inv)</th>\n",
       "      <th>1990</th>\n",
       "      <th>1995</th>\n",
       "      <th>2000</th>\n",
       "      <th>2005</th>\n",
       "      <th>2010</th>\n",
       "      <th>2015</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>CH4</td>\n",
       "      <td>Gg CH4 / yr</td>\n",
       "      <td>0</td>\n",
       "      <td>65.202</td>\n",
       "      <td>93.368</td>\n",
       "      <td>119.981</td>\n",
       "      <td>152.272</td>\n",
       "      <td>196.057</td>\n",
       "      <td>253.025</td>\n",
       "      <td>296.416</td>\n",
       "      <td>312.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>CH4</td>\n",
       "      <td>Gg CH4 / yr</td>\n",
       "      <td>1</td>\n",
       "      <td>6.465</td>\n",
       "      <td>7.066</td>\n",
       "      <td>6.489</td>\n",
       "      <td>5.984</td>\n",
       "      <td>4.849</td>\n",
       "      <td>5.360</td>\n",
       "      <td>5.931</td>\n",
       "      <td>5.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>CH4</td>\n",
       "      <td>Gg CH4 / yr</td>\n",
       "      <td>1.A</td>\n",
       "      <td>6.465</td>\n",
       "      <td>7.066</td>\n",
       "      <td>6.489</td>\n",
       "      <td>5.984</td>\n",
       "      <td>4.849</td>\n",
       "      <td>5.360</td>\n",
       "      <td>5.931</td>\n",
       "      <td>5.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>CH4</td>\n",
       "      <td>Gg CH4 / yr</td>\n",
       "      <td>1.A.1</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>CH4</td>\n",
       "      <td>Gg CH4 / yr</td>\n",
       "      <td>1.A.2</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>SO2</td>\n",
       "      <td>Gg SO2 / yr</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>SO2</td>\n",
       "      <td>Gg SO2 / yr</td>\n",
       "      <td>M.BK</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>SO2</td>\n",
       "      <td>Gg SO2 / yr</td>\n",
       "      <td>M.BK.A</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>SO2</td>\n",
       "      <td>Gg SO2 / yr</td>\n",
       "      <td>M.BK.M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>GIN-GHG-Inventory</td>\n",
       "      <td>BUR1</td>\n",
       "      <td>measured</td>\n",
       "      <td>GIN</td>\n",
       "      <td>SO2</td>\n",
       "      <td>Gg SO2 / yr</td>\n",
       "      <td>M.MULTIOP</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>543 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                source scenario (PRIMAP) provenance area (ISO3) entity  \\\n",
       "0    GIN-GHG-Inventory              BUR1   measured         GIN    CH4   \n",
       "1    GIN-GHG-Inventory              BUR1   measured         GIN    CH4   \n",
       "2    GIN-GHG-Inventory              BUR1   measured         GIN    CH4   \n",
       "3    GIN-GHG-Inventory              BUR1   measured         GIN    CH4   \n",
       "4    GIN-GHG-Inventory              BUR1   measured         GIN    CH4   \n",
       "..                 ...               ...        ...         ...    ...   \n",
       "538  GIN-GHG-Inventory              BUR1   measured         GIN    SO2   \n",
       "539  GIN-GHG-Inventory              BUR1   measured         GIN    SO2   \n",
       "540  GIN-GHG-Inventory              BUR1   measured         GIN    SO2   \n",
       "541  GIN-GHG-Inventory              BUR1   measured         GIN    SO2   \n",
       "542  GIN-GHG-Inventory              BUR1   measured         GIN    SO2   \n",
       "\n",
       "            unit category (IPCC1996_2006_GIN_Inv)    1990    1995     2000  \\\n",
       "0    Gg CH4 / yr                                0  65.202  93.368  119.981   \n",
       "1    Gg CH4 / yr                                1   6.465   7.066    6.489   \n",
       "2    Gg CH4 / yr                              1.A   6.465   7.066    6.489   \n",
       "3    Gg CH4 / yr                            1.A.1   0.032   0.027    0.024   \n",
       "4    Gg CH4 / yr                            1.A.2   0.006   0.012    0.018   \n",
       "..           ...                              ...     ...     ...      ...   \n",
       "538  Gg SO2 / yr                                5     NaN     NaN      NaN   \n",
       "539  Gg SO2 / yr                             M.BK   0.000   0.000    0.000   \n",
       "540  Gg SO2 / yr                           M.BK.A   0.000   0.000    0.000   \n",
       "541  Gg SO2 / yr                           M.BK.M     NaN     NaN      NaN   \n",
       "542  Gg SO2 / yr                        M.MULTIOP   0.000   0.000    0.000   \n",
       "\n",
       "        2005     2010     2015     2018     2019  \n",
       "0    152.272  196.057  253.025  296.416  312.034  \n",
       "1      5.984    4.849    5.360    5.931    5.866  \n",
       "2      5.984    4.849    5.360    5.931    5.866  \n",
       "3      0.020    0.016    0.002    0.005    0.001  \n",
       "4      0.023    0.028    0.024    0.026    0.033  \n",
       "..       ...      ...      ...      ...      ...  \n",
       "538      NaN      NaN      NaN      NaN      NaN  \n",
       "539    0.000    0.000    0.000    0.000    0.000  \n",
       "540    0.000    0.000    0.000    0.000    0.000  \n",
       "541      NaN      NaN      NaN      NaN      NaN  \n",
       "542    0.000    0.000    0.000    0.000    0.000  \n",
       "\n",
       "[543 rows x 15 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trend_all = pd.concat([df_main_dict['131'],\n",
    "                          df_main_dict['132'],\n",
    "                          df_main_dict['133'],\n",
    "                          df_main_dict['134'],\n",
    "                          df_main_dict['135'],\n",
    "                          df_main_dict['136'],\n",
    "                          df_main_dict['137'],\n",
    "                         ], axis=0, join='outer').reset_index(drop=True)\n",
    "\n",
    "df_trend_IF = pm2.pm2io.convert_long_dataframe_if(\n",
    "    df_trend_all,\n",
    "    coords_cols=coords_cols,\n",
    "    #add_coords_cols=add_coords_cols,\n",
    "    coords_defaults=coords_defaults,\n",
    "    coords_terminologies=coords_terminologies,\n",
    "    coords_value_mapping=coords_value_mapping['trend'],\n",
    "    #coords_value_filling=coords_value_filling,\n",
    "    filter_remove=filter_remove,\n",
    "    #filter_keep=filter_keep,\n",
    "    meta_data=meta_data,\n",
    "    convert_str=True,\n",
    "    time_format=\"%Y\",\n",
    "    )\n",
    "    \n",
    "df_trend_IF\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03d3fcd8-f3f5-46ad-b88c-00c42e7b9624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CH4', 'CO', 'CO2', 'N2O', 'NMVOC', 'NOx', 'SO2'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"M.BK\") & (df_trend_IF[\"entity\"] == \"N2O\") , \"2019\"]\n",
    "df_trend_IF['entity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1d7bffa-b778-4c18-8783-1dbfb8cafbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# values in main table are assumed to be correct\n",
    "#df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"3.D\") & (df_trend_IF[\"entity\"] == \"CO2\") , \"2019\"] = 0\n",
    "#df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"3.D.1\") & (df_trend_IF[\"entity\"] == \"CO2\") , \"2019\"] = np.nan\n",
    "\n",
    "# CH4 - values in main table are assumed to be correct\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"M.BK\") & (df_trend_IF[\"entity\"] == \"CH4\") , \"1990\"] = np.nan\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"M.BK.A\") & (df_trend_IF[\"entity\"] == \"CH4\") , \"1990\"] = np.nan\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"M.BK\") & (df_trend_IF[\"entity\"] == \"CH4\") , \"2000\"] = np.nan\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"M.BK.A\") & (df_trend_IF[\"entity\"] == \"CH4\") , \"2000\"] = np.nan\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"M.BK\") & (df_trend_IF[\"entity\"] == \"CH4\") , \"2010\"] = np.nan\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"M.BK.A\") & (df_trend_IF[\"entity\"] == \"CH4\") , \"2010\"] = np.nan\n",
    "\n",
    "# CO - values in main table are assumed to be correct\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"1.A.2\") & (df_trend_IF[\"entity\"] == \"CO\") , \"1990\"] = np.nan\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"M.BK\") & (df_trend_IF[\"entity\"] == \"CO\") , \"1990\"] = np.nan\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"M.BK.A\") & (df_trend_IF[\"entity\"] == \"CO\") , \"1990\"] = np.nan\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"M.BK\") & (df_trend_IF[\"entity\"] == \"CO\") , \"2000\"] = np.nan\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"M.BK.A\") & (df_trend_IF[\"entity\"] == \"CO\") , \"2000\"] = np.nan\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"M.BK\") & (df_trend_IF[\"entity\"] == \"CO\") , \"2010\"] = np.nan\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"M.BK.A\") & (df_trend_IF[\"entity\"] == \"CO\") , \"2010\"] = np.nan\n",
    "\n",
    "# N2O - values in main table are assumed to be correct\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"1.A.2\") & (df_trend_IF[\"entity\"] == \"N2O\") , \"1990\"] = np.nan\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"M.BK\") & (df_trend_IF[\"entity\"] == \"N2O\") , \"1990\"] = np.nan\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"M.BK.A\") & (df_trend_IF[\"entity\"] == \"N2O\") , \"1990\"] = np.nan\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"M.BK\") & (df_trend_IF[\"entity\"] == \"N2O\") , \"2000\"] = np.nan\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"M.BK.A\") & (df_trend_IF[\"entity\"] == \"N2O\") , \"2000\"] = np.nan\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"M.BK\") & (df_trend_IF[\"entity\"] == \"N2O\") , \"2010\"] = np.nan\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"M.BK.A\") & (df_trend_IF[\"entity\"] == \"N2O\") , \"2010\"] = np.nan\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"M.BK\") & (df_trend_IF[\"entity\"] == \"N2O\") , \"2019\"] = np.nan\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"M.BK.A\") & (df_trend_IF[\"entity\"] == \"N2O\") , \"2019\"] = np.nan\n",
    "\n",
    "# NOx - values in main table are assumed to be correct\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"3.C\") & (df_trend_IF[\"entity\"] == \"NOx\") , \"2019\"] = np.nan\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"3.C.1\") & (df_trend_IF[\"entity\"] == \"NOx\") , \"2019\"] = np.nan\n",
    "df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == \"3\") & (df_trend_IF[\"entity\"] == \"NOx\") , \"2019\"] = np.nan\n",
    "\n",
    "# NMVOC - values in main table are assumed to be correct\n",
    "entity = 'NMVOC'\n",
    "for category, year in [\n",
    "    ('0', '2000'),\n",
    "    ('1', '2000'),\n",
    "    ('1.A','2000'),\n",
    "    ('1.A.1','2000'),\n",
    "    ('1.A.2','2000'),\n",
    "    ('1.A.3','2000'),\n",
    "    ('1.A.4','2000'),\n",
    "    ('2','2000'),\n",
    "    ('2.H', '2000'),\n",
    "    ('2.H.2', '2000'),\n",
    "    ('0','2010'),\n",
    "    ('1','2010'),\n",
    "    ('1.A','2010'),\n",
    "    ('1.A.1','2010'),\n",
    "    ('1.A.2','2010'),\n",
    "    ('1.A.3','2010'),\n",
    "    ('1.A.4','2010'),\n",
    "    ('2','2010'),\n",
    "]:\n",
    "    df_trend_IF.loc[(df_trend_IF[\"category (IPCC1996_2006_GIN_Inv)\"] == category) & (df_trend_IF[\"entity\"] == entity) , year] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad6ba48c-b25d-4038-afaa-4f19f934b7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CH4', 'CO', 'CO2', 'N2O', 'NMVOC', 'NOx', 'SO2'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trend_IF['entity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05e1ad4f-c35c-460c-8546-5e493f363739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-29 12:30:08.695\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2.pm2io._interchange_format\u001b[0m:\u001b[36mfrom_interchange_format\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1mExpected array shapes: [[1, 1, 1, 1, 7, 78], [1, 1, 1, 1, 7, 78], [1, 1, 1, 1, 7, 78], [1, 1, 1, 1, 7, 78], [1, 1, 1, 1, 7, 78], [1, 1, 1, 1, 7, 78], [1, 1, 1, 1, 7, 78]], resulting in size 3,822.\u001b[0m\n",
      "/Users/danielbusch/Documents/UNFCCC_non-AnnexI_data/venv/lib/python3.10/site-packages/primap2/_data_format.py:481: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  all_dims = set(ds.dims.keys())\n",
      "\u001b[32m2024-03-29 12:30:08.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprimap2._data_format\u001b[0m:\u001b[36mensure_valid_attributes\u001b[0m:\u001b[36m292\u001b[0m - \u001b[1mReference information is not a DOI: 'https://unfccc.int/BURs'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### convert to primap2 format ###\n",
    "data_pm2_trend = pm2.pm2io.from_interchange_format(df_trend_IF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b65227-b7c4-4d18-89ef-af927c9a81b5",
   "metadata": {},
   "source": [
    "# Combine tables and save to IF and native format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "960117b6-28fc-45ba-a768-16f63e428875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-29 12:30:13.712\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for NMVOC\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:14.118\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for N2O\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:14.408\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for CH4\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:14.701\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for CO2\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:14.993\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for SO2\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:15.176\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for CO\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:15.468\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for NOx\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#### combine\n",
    "\n",
    "\n",
    "# discrepancies larger than 0.86 for area (ISO3)=GIN,\n",
    "# category (IPCC1996_2006_GIN_Inv)=1.A.2, entity=NMVOC\n",
    "# 1990-01-01  0.800000, 2000-01-01  0.800000, 2010-01-01  0.869848\n",
    "# and\n",
    "# (ISO3)=GIN, category (IPCC1996_2006_GIN_Inv)=1.A.2, time=1262304000000000000 (2019?)\n",
    "# The values in the table are different / one is wrong\n",
    "# merge main and energy\n",
    "data_pm2 = data_pm2_main.pr.merge(data_pm2_energy,tolerance=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c426f4fa-d205-4bb1-9e9a-189c365fb68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-29 12:30:18.578\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for NMVOC\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:19.081\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for N2O\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:19.369\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for CH4\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:19.802\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for CO2\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:20.230\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for CO\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:20.483\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for NOx\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# merge lulucf \n",
    "data_pm2 = data_pm2.pr.merge(data_pm2_lulucf,tolerance=0.11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3aac0b03-08bb-4699-84c3-bc0994ea231a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-29 12:30:23.522\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for NMVOC\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:23.995\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for N2O\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:24.443\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for CH4\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:24.730\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for CO2\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:25.020\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for SO2\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:25.289\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for CO\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:25.552\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for NOx\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# merge waste \n",
    "# increasing tolerance to merge values for 4.C, 1990, N2O - 0.003 in sector table, 0.0034 in main table\n",
    "data_pm2 = data_pm2.pr.merge(data_pm2_waste,tolerance=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18ff30b7-b6ff-4c41-b82d-3f0935d9cec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-29 12:30:27.515\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for NMVOC\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:27.636\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for N2O\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:27.727\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for CH4\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:27.818\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for CO2\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:27.909\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for SO2\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:27.998\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for CO\u001b[0m\n",
      "\u001b[32m2024-03-29 12:30:28.035\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mprimap2._merge\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m230\u001b[0m - \u001b[34m\u001b[1mmerging for NOx\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data_pm2 = data_pm2.pr.merge(data_pm2_trend,tolerance=0.11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3cb74c9e-b400-454b-848a-28091b832016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert back to IF to have units in the fixed format ( per year / per a / per annum)\n",
    "data_if = data_pm2.pr.to_interchange_format()\n",
    "\n",
    "# ###\n",
    "# save data to IF and native format\n",
    "# ###\n",
    "#pm2.pm2io.write_interchange_format(\n",
    "#    output_folder / (output_filename + coords_terminologies[\"category\"] + \"_raw\"), data_if)\n",
    "\n",
    "#encoding = {var: compression for var in data_pm2.data_vars}\n",
    "#data_pm2.pr.to_netcdf(\n",
    "#    output_folder / (output_filename + coords_terminologies[\"category\"] + \"_raw.nc\"),\n",
    "#    encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0530fffe-3d12-4697-b341-fa54ffca367b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '1.A', '1.A.1', '1.A.1.a', '1.A.1.a.i', '1.A.2',\n",
       "       '1.A.2.c', '1.A.2.e', '1.A.2.f', '1.A.2.i', '1.A.2.k', '1.A.2.m',\n",
       "       '1.A.3', '1.A.3.a', '1.A.3.a.i', '1.A.3.a.ii', '1.A.3.b',\n",
       "       '1.A.3.c', '1.A.3.d', '1.A.3.d.ii', '1.A.4', '1.A.4.b', '1.A.4.c',\n",
       "       '1.A.4.c.i', '1.A.5', '2', '2.A', '2.C', '2.C.2', '2.D', '2.D.4',\n",
       "       '2.F', '2.H', '2.H.2', '3', '3.A', '3.A.1', '3.A.1.a', '3.A.1.a.i',\n",
       "       '3.A.1.a.ii', '3.A.1.c', '3.A.1.d', '3.A.1.h', '3.A.2', '3.A.2.a',\n",
       "       '3.A.2.a.i', '3.A.2.a.ii', '3.A.2.c', '3.A.2.d', '3.A.2.h',\n",
       "       '3.A.2.i', '3.A.2.j', '3.B', '3.B.1', '3.B.1.b', '3.B.2',\n",
       "       '3.B.2.b', '3.B.3', '3.B.3.b', '3.B.4', '3.B.4.a', '3.B.4.b',\n",
       "       '3.B.5', '3.B.5.b', '3.B.6', '3.B.6.b', '3.C', '3.C.1', '3.C.1.c',\n",
       "       '3.C.7', '3.C.8', '3.D', '3.D.2', '4', '4.A', '4.B', '4.C',\n",
       "       '4.C.2', '4.D', '4.D.1', '4.D.2', '4.E', 'M.BK', 'M.BK.A',\n",
       "       'M.MULTIOP', '1.A.3.e', '2.A.1', '2.D.1', '2.F.1', '3.B.1.a',\n",
       "       '3.B.1.b.i', '3.B.1.b.ii', '3.B.1.b.iii', '3.B.1.b.iv',\n",
       "       '3.B.1.b.v', '3.B.2.a', '3.B.2.b.i', '3.B.2.b.ii', '3.B.2.b.iii',\n",
       "       '3.B.2.b.iv', '3.B.2.b.v', '3.B.3.a', '3.B.3.b.i', '3.B.3.b.ii',\n",
       "       '3.B.3.b.iii', '3.B.3.b.iv', '3.B.3.b.v', '3.B.4.a.i',\n",
       "       '3.B.4.a.ii', '3.B.5.a', '3.B.6.a', '3.C.2', '3.C.3', '3.C.4',\n",
       "       '3.C.5', '3.C.6', '3.D.1', '4.A.2', '4.A.3'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for i in pd.Series(data_if['category (IPCC1996_2006_GIN_Inv)'].unique()).sort_values():\n",
    "#    print(i)\n",
    "#data_if.loc[(data_if[\"category (IPCC1996_2006_GIN_Inv)\"] == '3.D.2')]\n",
    "data_if['category (IPCC1996_2006_GIN_Inv)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9619c2fa-795a-4c11-914b-215cf0e707f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_proc_pm2 = data_pm2\n",
    "\n",
    "country_processing_step1 = {\n",
    "    'aggregate_cats': {\n",
    "        'M.3.C.AG': {'sources': ['3.C.1', '3.C.2', '3.C.3', '3.C.4', '3.C.5',\n",
    "                                 '3.C.6', '3.C.7', '3.C.8'],\n",
    "                     'name': 'Aggregate sources and non-CO2 emissions sources on land '\n",
    "                             '(Agriculture)'},\n",
    "        'M.3.D.AG': {'sources': ['3.D.2'],\n",
    "                     'name': 'Other (Agriculture)'},\n",
    "        'M.AG.ELV': {'sources': ['M.3.C.AG', 'M.3.D.AG'],\n",
    "                     'name': 'Agriculture excluding livestock'},\n",
    "        'M.AG': {'sources': ['3.A', 'M.AG.ELV'],\n",
    "                     'name': 'Agriculture'},\n",
    "        'M.3.D.LU': {'sources': ['3.D.1'],\n",
    "                     'name': 'Other (LULUCF)'},\n",
    "        'M.LULUCF': {'sources': ['3.B', 'M.3.D.LU'],\n",
    "                     'name': 'LULUCF'},\n",
    "        'M.0.EL': {'sources': ['1', '2', 'M.AG', '4'],\n",
    "                     'name': 'National total emissions excluding LULUCF'},\n",
    "    },\n",
    "    'basket_copy': {\n",
    "        'GWPs_to_add': [\"SARGWP100\", \"AR5GWP100\", \"AR6GWP100\"],\n",
    "        'entities': [\"HFCS\", \"PFCS\"],\n",
    "        'source_GWP': gwp_to_use,\n",
    "    },\n",
    "}\n",
    "\n",
    "gas_baskets = {\n",
    "    'FGASES (SARGWP100)': ['HFCS (SARGWP100)', 'PFCS (SARGWP100)', 'SF6', 'NF3'],\n",
    "    'FGASES (AR4GWP100)': ['HFCS (AR4GWP100)', 'PFCS (AR4GWP100)', 'SF6', 'NF3'],\n",
    "    'FGASES (AR5GWP100)':['HFCS (AR5GWP100)', 'PFCS (AR5GWP100)', 'SF6', 'NF3'],\n",
    "    'FGASES (AR6GWP100)':['HFCS (AR6GWP100)', 'PFCS (AR6GWP100)', 'SF6', 'NF3'],\n",
    "    'KYOTOGHG (SARGWP100)': ['CO2', 'CH4', 'N2O', 'FGASES (SARGWP100)'],\n",
    "    'KYOTOGHG (AR4GWP100)': ['CO2', 'CH4', 'N2O', 'FGASES (AR4GWP100)'],\n",
    "    'KYOTOGHG (AR5GWP100)': ['CO2', 'CH4', 'N2O', 'FGASES (AR5GWP100)'],\n",
    "    'KYOTOGHG (AR6GWP100)': ['CO2', 'CH4', 'N2O', 'FGASES (AR6GWP100)'],\n",
    "}\n",
    "\n",
    "# actual processing\n",
    "#data_proc_pm2 = process_data_for_country(\n",
    "#    data_proc_pm2,\n",
    "#    gas_baskets=gas_baskets,\n",
    "#    entities_to_ignore=[],\n",
    "#    processing_info_country=country_processing_step1,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e57d214b-1e59-40df-a799-fa0cdb33f86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# All steps from process_data_for_country\n",
    "# \"\"\"\n",
    "# Process data from DI interface (where necessary).\n",
    "# * Downscaling including subtraction of time series\n",
    "# * country specific sector aggregation\n",
    "# * Conversion to IPCC2006 categories\n",
    "# * general sector and gas basket aggregation (in new categories)\n",
    "# \"\"\"\n",
    "entities_to_ignore=[],\n",
    "processing_info_country=country_processing_step1,\n",
    "\n",
    "# 0: gather information\n",
    "data_country = data_proc_pm2\n",
    "countries = list(data_country.coords[data_country.attrs[\"area\"]].values)\n",
    "if len(countries) > 1:\n",
    "    raise ValueError(\n",
    "        f\"Found {len(countries)} countries. Only single country data \"\n",
    "        f\"can be processed by this function. countries: {countries}\"\n",
    "    )\n",
    "else:\n",
    "    country_code = countries[0]\n",
    "\n",
    "# get category terminology\n",
    "cat_col = data_country.attrs[\"cat\"]\n",
    "temp = re.findall(r\"\\((.*)\\)\", cat_col)\n",
    "cat_terminology_in = temp[0]\n",
    "\n",
    "# get scenario\n",
    "scenarios = list(data_country.coords[data_country.attrs[\"scen\"]].values)\n",
    "if len(scenarios) > 1:\n",
    "    raise ValueError(\n",
    "        f\"Found {len(scenarios)} scenarios. Only single scenario data \"\n",
    "        f\"can be processed by this function. Scenarios: {scenarios}\"\n",
    "    )\n",
    "scenario = scenarios[0]\n",
    "\n",
    "# get source\n",
    "sources = list(data_country.coords[\"source\"].values)\n",
    "if len(sources) > 1:\n",
    "    raise ValueError(\n",
    "        f\"Found {len(sources)} sources. Only single source data \"\n",
    "        f\"can be processed by this function. Sources: {sources}\"\n",
    "    )\n",
    "source = sources[0]\n",
    "\n",
    "# check if category name column present\n",
    "# TODO: replace 'name' in config by  'additional_cols' dict that defines the cols\n",
    "#  and the values\n",
    "if \"orig_cat_name\" in data_country.coords:\n",
    "    cat_name_present = True\n",
    "else:\n",
    "    cat_name_present = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23cda172-726e-4405-b14e-3ae2060b78e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing all-nan variables: []\n"
     ]
    }
   ],
   "source": [
    "# 1: general processing\n",
    "# remove unused cats\n",
    "data_country = data_country.dropna(f\"category ({cat_terminology_in})\", how=\"all\")\n",
    "# remove unused years\n",
    "data_country = data_country.dropna(f\"time\", how=\"all\")\n",
    "# remove variables only containing nan\n",
    "nan_vars_country = [\n",
    "    var\n",
    "    for var in data_country.data_vars\n",
    "    if bool(data_country[var].isnull().all().data) is True\n",
    "]\n",
    "print(f\"removing all-nan variables: {nan_vars_country}\")\n",
    "data_country = data_country.drop_vars(nan_vars_country)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53b0b886-554e-4535-b4ee-cf1fcbf8db3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating categories for country GIN, source GIN-GHG-Inventory, scenario BUR1\n",
      "Category: M.3.C.AG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/1732274552.py:22: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
      "  data_agg = data_agg.drop(nan_vars)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: M.3.D.AG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/1732274552.py:22: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
      "  data_agg = data_agg.drop(nan_vars)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: M.AG.ELV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/1732274552.py:22: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
      "  data_agg = data_agg.drop(nan_vars)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: M.AG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/1732274552.py:22: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
      "  data_agg = data_agg.drop(nan_vars)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: M.3.D.LU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/1732274552.py:22: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
      "  data_agg = data_agg.drop(nan_vars)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: M.LULUCF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/1732274552.py:22: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
      "  data_agg = data_agg.drop(nan_vars)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: M.0.EL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/tt5f76gd0q139kzgw6b9m8l40000gn/T/ipykernel_10373/1732274552.py:22: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
      "  data_agg = data_agg.drop(nan_vars)\n"
     ]
    }
   ],
   "source": [
    "tolerance = 0.01\n",
    "agg_tolerance = tolerance\n",
    "\n",
    "aggregate_cats_current = country_processing_step1[\"aggregate_cats\"]\n",
    "\n",
    "print(\n",
    "    f\"Aggregating categories for country {country_code}, source {source}, \"\n",
    "    f\"scenario {scenario}\"\n",
    ")\n",
    "for cat_to_agg in aggregate_cats_current:\n",
    "    print(f\"Category: {cat_to_agg}\")\n",
    "    source_cats = aggregate_cats_current[cat_to_agg][\"sources\"]\n",
    "    data_agg = data_country.pr.loc[{\"category\": source_cats}].pr.sum(\n",
    "        dim=\"category\", skipna=True, min_count=1\n",
    "    )\n",
    "    #data_agg = data_country.pr.loc[{\"category\": source_cats}]\n",
    "    nan_vars = [\n",
    "        var\n",
    "        for var in data_agg.data_vars\n",
    "        if data_agg[var].isnull().all().data is True\n",
    "    ]\n",
    "    data_agg = data_agg.drop(nan_vars)\n",
    "    if len(data_agg.data_vars) > 0:\n",
    "        data_agg = data_agg.expand_dims(\n",
    "            [f\"category (\" f\"{cat_terminology_in})\"]\n",
    "        )\n",
    "        data_agg = data_agg.assign_coords(\n",
    "            coords={\n",
    "                f\"category ({cat_terminology_in})\": (\n",
    "                    f\"category ({cat_terminology_in})\",\n",
    "                    [cat_to_agg],\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "        if cat_name_present:\n",
    "            cat_name = aggregate_cats_current[cat_to_agg][\"name\"]\n",
    "            data_agg = data_agg.assign_coords(\n",
    "                coords={\n",
    "                    \"orig_cat_name\": (\n",
    "                        f\"category ({cat_terminology_in})\",\n",
    "                        [cat_name],\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "        data_country = data_country.pr.merge(\n",
    "            data_agg, tolerance=agg_tolerance\n",
    "        )\n",
    "    else:\n",
    "        print(f\"no data to aggregate category {cat_to_agg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b392380-7c95-4ed2-974a-c909fefe9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from UNFCCC_GHG_data.helper import GWP_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "419b6bb7-9e2b-40b7-b73d-e3e732a03fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy HFCs and PFCs with default factors\n",
    "GWPs_to_add = country_processing_step1[\"basket_copy\"][\"GWPs_to_add\"]\n",
    "entities = country_processing_step1[\"basket_copy\"][\"entities\"]\n",
    "source_GWP = country_processing_step1[\"basket_copy\"][\"source_GWP\"]\n",
    "for entity in entities:\n",
    "    data_source = data_country[f\"{entity} ({source_GWP})\"]\n",
    "    for GWP in GWPs_to_add:\n",
    "        data_GWP = (\n",
    "            data_source * GWP_factors[f\"{source_GWP}_to_{GWP}\"][entity]\n",
    "        )\n",
    "        data_GWP.attrs[\"entity\"] = entity\n",
    "        data_GWP.attrs[\"gwp_context\"] = GWP\n",
    "        data_country[f\"{entity} ({GWP})\"] = data_GWP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "661993cd-5c21-44d2-8177-bf20a45f90ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ccf0224-ca38-4bc4-9096-863a35c9dfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create gas baskets\n",
    "entities_present = set(data_country.data_vars)\n",
    "for basket in gas_baskets.keys():\n",
    "    basket_contents_present = [\n",
    "        gas for gas in gas_baskets[basket] if gas in entities_present\n",
    "    ]\n",
    "    if len(basket_contents_present) > 0:\n",
    "        if basket in list(data_country.data_vars):\n",
    "            data_country[basket] = data_country.pr.fill_na_gas_basket_from_contents(\n",
    "                basket=basket,\n",
    "                basket_contents=basket_contents_present,\n",
    "                skipna=True,\n",
    "                min_count=1,\n",
    "            )\n",
    "        else:\n",
    "            try:\n",
    "                # print(data_country.data_vars)\n",
    "                data_country[basket] = xr.full_like(\n",
    "                    data_country[\"CO2\"], np.nan\n",
    "                ).pr.quantify(units=\"Gg CO2 / year\")\n",
    "                data_country[basket].attrs = {\n",
    "                    \"entity\": basket.split(\" \")[0],\n",
    "                    \"gwp_context\": basket.split(\" \")[1][1:-1],\n",
    "                }\n",
    "                data_country[basket] = data_country.pr.gas_basket_contents_sum(\n",
    "                    basket=basket,\n",
    "                    basket_contents=basket_contents_present,\n",
    "                    min_count=1,\n",
    "                )\n",
    "                entities_present.add(basket)\n",
    "            except Exception as ex:\n",
    "                print(\n",
    "                    f\"No gas basket created for {country_code}, {source}, \"\n",
    "                    f\"{scenario}: {ex}\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eda178a3-7fd1-4c58-b130-09e1b28170bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba9394da-88c2-4e7c-afb2-05a083aacf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amend title and comment\n",
    "data_country.attrs[\"comment\"] = (\n",
    "    data_country.attrs[\"comment\"] + f\" Processed on \" f\"{date.today()}\"\n",
    ")\n",
    "data_country.attrs[\"title\"] = (\n",
    "    data_country.attrs[\"title\"] + f\" Processed on \" f\"{date.today()}\"\n",
    ")\n",
    "\n",
    "data_proc_pm2 = data_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d764507e-5f81-4998-ac1c-c55b740f3af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e307e89-dfb4-48d6-8bf8-e401a2fc31a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###\n",
    "# save data to IF and native format\n",
    "# ###\n",
    "terminology_proc = coords_terminologies['category']\n",
    "\n",
    "data_proc_if = data_proc_pm2.pr.to_interchange_format()\n",
    "if not output_folder.exists():\n",
    "    output_folder.mkdir()\n",
    "pm2.pm2io.write_interchange_format(\n",
    "    output_folder / (output_filename + terminology_proc), data_proc_if)\n",
    "\n",
    "encoding = {var: compression for var in data_proc_pm2.data_vars}\n",
    "data_proc_pm2.pr.to_netcdf(\n",
    "    output_folder / (output_filename + terminology_proc + \".nc\"),\n",
    "    encoding=encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf5e24c-3d02-4afd-9705-18867749c996",
   "metadata": {},
   "source": [
    "# Annex (maybe not needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d0430e-7a6a-4b47-96b1-166ec129cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_agg = data_agg.pr.sum(dim=\"category\", skipna=True, min_count=1)\n",
    "#test_if = data_agg\n",
    "#test_if = test_if.pr.sum(dim=\"entity\", skipna=True, min_count=1)\n",
    "#test_if.pr.to_interchange_format()\n",
    "#type(data_agg.pr.to_interchange_format())\n",
    "data_agg.pr.to_interchange_format()\n",
    "#data_agg.sum(dim=\"category (IPCC1996_2006_GIN_Inv)\", skipna=True, min_count=1).pr.to_interchange_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30257c41-9c0d-44c1-bda9-4b0c29a1ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category aggregation\n",
    "# aggregate cats in process_data_for_country\n",
    "# processing for removals not neccessary here\n",
    "# - all sectors need to be present: we probably need sector M.AG (3.A, parts of 3.C and parts of M.A)\n",
    "# aggregate categories, check Malaysia config, check table IPCC1996 / IPCC2006 category table \n",
    "\n",
    "data_proc_pm2 = data_pm2\n",
    "\n",
    "# actual processing\n",
    "data_proc_pm2 = process_data_for_country(\n",
    "    data_proc_pm2,\n",
    "    gas_baskets=gas_baskets,\n",
    "    entities_to_ignore=[],\n",
    "    processing_info_country=country_processing_step1,\n",
    ")\n",
    "\n",
    "'AND_BUR2': {\n",
    "    # '3.A': {'sources': ['3.A.1', '3.A.2'], 'name': 'Livestock'},\n",
    "    'M.3.C.1.AG': {'sources': ['3.C.1.b', '3.C.1.c'], 'name': 'Emissions from Biomass Burning (Agriculture)'},\n",
    "    'M.3.C.1.LU': {'sources': ['3.C.1.a', '3.C.1.d'], 'name': 'Emissions from Biomass Burning (LULUCF)'},\n",
    "    # '3.C.1': {'sources': ['M.3.C.1AG', 'M.3.C.1LU'], 'name': 'Emissions from Biomass Burning'},\n",
    "    # '3.C': {'sources': ['3.C.1', '3.C.2', '3.C.3', '3.C.4', '3.C.5', '3.C.6', '3.C.7', '3.C.8'],\n",
    "    #        'name': 'Aggregate sources and non-CO2 emissions sources on land'},\n",
    "    'M.3.C.AG': {'sources': ['M.3.C.1.AG', '3.C.2', '3.C.3', '3.C.4', '3.C.5', '3.C.6', '3.C.7', '3.C.8'],\n",
    "                 'name': 'Aggregate sources and non-CO2 emissions sources on land (Agriculture)'},\n",
    "    'M.AG.ELV': {'sources': ['M.3.C.AG'], 'name': 'Agriculture excluding livestock emissions'},\n",
    "    'M.AG': {'sources': ['3.A', 'M.AG.ELV'], 'name': 'Agriculture'},\n",
    "    'M.LULUCF': {'sources': ['3.B', 'M.3.C.1.LU', '3.D.1'], 'name': 'Land Use, Land Use Change, and Forestry'},\n",
    "    # '3': {'sources': ['M.AG', 'M.LULUCF'], 'name': 'AFOLU'},\n",
    "    '0': {'sources': ['1', '2', '3', '4'], 'name': 'National Total'},\n",
    "    'M.0.EL': {'sources': ['1', '2', 'M.AG', '4'], 'name': 'National Total Excluding LULUCF'},\n",
    "},\n",
    "\n",
    "# all 3.D, M.3.LU to M.LULUCF\n",
    "# M.0.EL is missing in Guinea report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1bd11b-3ede-4fc5-93cb-26ec2e496570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc34733a-919b-4d11-a300-f4a3695a0a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gas baskets\n",
    "# docs im repo anschauen\n",
    "# TODO:  downscaling\n",
    "\n",
    "# \n",
    "data_proc_pm2 = process_data_for_country(\n",
    "    data_proc_pm2,\n",
    "    entities_to_ignore=[],\n",
    "    gas_baskets=gas_baskets,\n",
    "    processing_info_country=country_processing_step2, # maybe step 2 not necessary\n",
    "    cat_terminology_out = terminology_proc,\n",
    "    category_conversion = cat_conversion, # probably not\n",
    "    sectors_out = sectors_to_save,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c51a283-4657-48b3-830a-ca0e6ef0c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###\n",
    "# ## process the data\n",
    "# ###\n",
    "data_proc_pm2 = data_pm2\n",
    "\n",
    "# combine CO2 emissions and removals\n",
    "#data_proc_pm2[\"CO2\"] = data_proc_pm2[[\"CO2 emissions\", \"CO2 removals\"]].pr.sum\\\n",
    "#    (dim=\"entity\", skipna=True, min_count=1)\n",
    "#data_proc_pm2[\"CO2\"].attrs['entity'] = 'CO2'\n",
    "\n",
    "# aggregate gase\n",
    "# basket copy: hfcs and pfcs\n",
    "# convert from AR4, see example Malaysia config BUR4 (country processing, basket copy, gas baskets)\n",
    "\n",
    "country_processing_step1 = { # not needed, will be done with gas baskets\n",
    "    'aggregate_gases': {\n",
    "        'KYOTOGHG': {\n",
    "            'basket': 'KYOTOGHG (AR4GWP100)',\n",
    "            'basket_contents': ['CO2', 'CH4', 'N2O', 'SF6',\n",
    "                                'HFCS (AR4GWP100)', 'PFCS (AR4GWP100)'],\n",
    "            'skipna': True,\n",
    "            'min_count': 1,\n",
    "            'sel': {f'category ({coords_terminologies[\"category\"]})':\n",
    "                [\n",
    "                    '0', '1', '1.A', '1.A.1', '1.A.2', '1.A.3',\n",
    "                    '1.A.4', '1.B', '1.B.1', '1.B.2',\n",
    "                    '1.C',\n",
    "                    '2', '2.A', '2.A.1', '2.A.2', '2.A.3', '2.A.4',\n",
    "                    '2.B', '2.C', '2.D', '2.H',\n",
    "                    '3', '3.A', '3.B', '3.C', '3.D', '3.E', '3.F', '3.G',\n",
    "                    '3.H', '3.I',\n",
    "                    '4', '4.A', '4.B', '4.C', '4.D', '4.E',\n",
    "                    '5', '5.A', '5.B', '5.C', '5.D'\n",
    "                ]\n",
    "            }, # not tested\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# actual processing\n",
    "data_proc_pm2 = process_data_for_country(\n",
    "    data_proc_pm2,\n",
    "    entities_to_ignore=[],\n",
    "    gas_baskets={},\n",
    "    processing_info_country=country_processing_step1,\n",
    ")\n",
    "\n",
    "# check if all data is float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50df93d4-a111-41ed-ba14-83fa4e82170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_proc_pm2 = process_data_for_country(\n",
    "    data_proc_pm2,\n",
    "    entities_to_ignore=[],\n",
    "    gas_baskets=gas_baskets,\n",
    "    processing_info_country=country_processing_step2,\n",
    "    cat_terminology_out = terminology_proc,\n",
    "    category_conversion = cat_conversion,\n",
    "    sectors_out = sectors_to_save,\n",
    ")\n",
    "\n",
    "# adapt source and metadata\n",
    "# TODO: processing info is present twice\n",
    "current_source = data_proc_pm2.coords[\"source\"].values[0]\n",
    "data_temp = data_proc_pm2.pr.loc[{\"source\": current_source}]\n",
    "data_proc_pm2 = data_proc_pm2.pr.set(\"source\", 'BUR_NIR', data_temp)\n",
    "\n",
    "# ###\n",
    "# save data to IF and native format\n",
    "# ###\n",
    "data_proc_if = data_proc_pm2.pr.to_interchange_format()\n",
    "if not output_folder.exists():\n",
    "    output_folder.mkdir()\n",
    "pm2.pm2io.write_interchange_format(\n",
    "    output_folder / (output_filename + terminology_proc), data_proc_if)\n",
    "\n",
    "encoding = {var: compression for var in data_proc_pm2.data_vars}\n",
    "data_proc_pm2.pr.to_netcdf(\n",
    "    output_folder / (output_filename + terminology_proc + \".nc\"),\n",
    "    encoding=encoding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
